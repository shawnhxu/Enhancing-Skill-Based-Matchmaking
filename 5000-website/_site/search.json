[
  {
    "objectID": "introduction.html",
    "href": "introduction.html",
    "title": "Introduction",
    "section": "",
    "text": "Chess Image Source\n\n\nIn this day and age, access to technology and internet connection has allowed for the culmination of numerous facets of human interaction. With the inclusion of online gaming services, there are even more ways of interacting with others through the form of games.\nMany types of games have been born because of these online gaming services with a popular form of this being competitive gameplay. Since competing against other human players can be more challenging and interesting, this form of gaming has become wildly popular in our modern times. Competitive games in their respective categories (MOBA, Shooter, Strategy, etc. games) have become so popular that they have their own “eSports” or electronic sports scenes being streamed on various broadcasting networks. It is an understatement to say that the gaming industry is big, it’s enormous.1 With how large the industry and consumer-base is, it is extremely important for guidelines to be put in place for popular competitive games to sustain their competitive scene and player base.\n\n\n\nEsports Image Source\n\n\nWith the popularity of competitive gaming and its future growth, a necessity to (1) create an enjoyable experience and (2) provide players an incentive to continue playing needs to be addressed by developers.2 Sometimes this falls into the realms of marketing and design, but in competitive games the essence of competition and fair-play are attributes that developers must pay attention to for players to keep playing.\nA way to answer both these issues in competitive video games is through the addition of a Skill Based Matchmaking (SBMM) system. This system aims to create balanced teams that have similar skill ratings in order to produce a competitive match. Though, many matchmaking systems are made so that a player’s skill rating is linearly determined by their past matches (wins and losses) compared to their opponents. Past created rating systems like Elo, Glicko, and Trueskill are some examples of these. 3 In the cited source, Aram Ebtekar and Paul Liu give this introduction to simple skill rating systems like Elo before moving onto their own novel algorithms that includes the simplicity of traditional skill rating systems while including Bayesian thinking. The purpose of this paper is to introduce their novel Bayesian rating systems for competition formats that include multiple participants. This is an approach that I wanted to investigate more into as I believe that the Elo system is well made but that the algorithm just needed a bit more tweaking to work in modern competitive team games.\nTo go more into these traditional rating systems, we can dive into the history of the Elo system to get an idea of the foundations of more advanced rating systems. At its core, a rating system hopes to determine how good a player is at a certain game. The elo system was made exactly for that reason in the Chess world. Developed by Professor Arpad Elo in 1959 for Chess, the Elo system essentially took the skill rating between two players going against each other to determine the probability of who will win the Chess match. Obviously, the better player of the two will most likely win and therefore have a higher probability. The other player will thus have a lower probability. From here, the binary result of the match (win/loss) will determine how much the losing player loses from their skill rating points and how much the winning player gains. In the Elo system, the winning player takes a certain amount of points from the losing player thus increasing their skill rating points and the losing player losing skill rating points. The system is unique in that the initial skill ratings of the players determine how much they lose/gain. Say the worse rated player took an underdog win against the better rated player, then the worse player will take a much higher amount of rating points from the better player. If the situation was flipped where the worse player loses to the better rated player as expected, then the amount taken from the worse player will be a lot less. This Elo system has even been adopted in other games like Scrabble and Go as well as sports like Tennis, Bowling, and Basketball.4\n\n\n\nElo Formula Image Source\n\n\nGoing back to modern competitive games, there are many more aspects of these games that must be taken into consideration. Many popular competitive games include aspects like teamplay and coordination. So an innately one-person scalar rating in the Elo system being used in team games can be troublesome to calculate a team’s skill rating. So to consider the idea of teamplay and coordination is crucial in creating an accurate skill rating. Going more into this, each player has their own style of playing the game and therefore using an outcome-based algorithm like the Elo system is dangerous. It does not capture the overall complexity of competitive team games. Another aspect that isn’t addressed in the Elo system is the measurement of an individual’s performance/effort in a specific match. If a player played well compared to their usual performance, then their efforts will be lost if their rating is determined solely by the outcome of the match.5 In this cited source, Aghdaie and et. al. examine how nonlinear models as a function of the players’ and teams’ features. Whats more interesting is that this article explains their metrics of success in their experimentations (how to determine if their rating system is good or not). They also illustrate their two different approaches to creating balanced matches with a probability of winning prediction model and their competitive balance prediction model. I hope to look more into this article and applying their findings in different mainstream competitive games.\nCurrently, skill rating algorithms is largely uncharted territory as many games employ different aspects of performace. Additionally, many ideas of how to build these rating algorithms are still in development. So in this final project I will go down the rabbit hole of skill rating systems. I plan to investigate different viewpoints of skill rating systems and use game developers’ open API’s to take in data from numerous games to find possible ways of improving skill rating systems in each of those video games."
  },
  {
    "objectID": "introduction.html#footnotes",
    "href": "introduction.html#footnotes",
    "title": "Introduction",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nhttps://www.grandviewresearch.com/industry-analysis/video-game-market#:~:text=b.-,The%20global%20video%20game%20market%20size%20was%20estimated%20at%20USD,USD%20583.69%20billion%20by%202030.↩︎\nhttps://www.microsoft.com/en-us/research/wp-content/uploads/2006/10/Game-Developer-Feature-Article-Graepel-Herbrich.pdf↩︎\nhttps://cs.stanford.edu/people/paulliu/files/www-2021-elor.pdf↩︎\nhttps://ieeexplore.ieee.org/abstract/document/4938634↩︎\nhttps://ieeexplore.ieee.org/abstract/document/9231859↩︎"
  },
  {
    "objectID": "eda.html",
    "href": "eda.html",
    "title": "Data Exploration",
    "section": "",
    "text": "The general packages I used and setting the theme of graphs:\n\n\nCode\n# Import packages\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\n\n# Apply the default theme\nsns.set_theme(style=\"whitegrid\", palette=\"pastel\")\n\n\nLoading in the dataset to EDA:\n\n\nCode\n#Import both Challenger and all other ranks Datasets (combined dataset)\ncombined_league_ranks = pd.read_csv('../../data/cleaned_riot_data/league_combined_with_chall_cleaned.csv')\n\n#Print the first few rows of the dataset\nprint(combined_league_ranks.head())\n\n\n     win  kills  deaths  dmgObj  dmgTurr  vision_score  totalDmg  \\\n0   True      3       2    6298     6298            10    148123   \n1  False      7       5    3222      424            15    116804   \n2   True     16       1   12446     2012            13    110153   \n3   True     13       2   10605     4966             9    148142   \n4   True      1       2    1430     1075            25     14254   \n\n   totalDmgTaken  totalMinions   gold position       time  rank  \n0          24127           197  11108   middle  29.150000  iron  \n1          24526           144  12407   middle  29.916667  iron  \n2          12996           145  13989   middle  28.433333  iron  \n3          26504           192  14154   middle  26.516667  iron  \n4          10728            19   7288  utility  25.100000  iron  \n\n\n\n\nAfter briefly looking at the dataset that I collected and cleaned, I notice that there are many unique variables being used in the columns. Namely there are 13 variables that I can look into individually. From the dataset, I can tell that it is mostly numeric data with one float variable (time), two string variables (rank and position), and one Boolean column (win). The rest being numeric variables. For the sake of my later analysis with Naive Bayes, I will assume that these variables are independent. However, I believe there are some major correlation with these variables. One that sticks out to me is the time column with columns like gold earned, minions killed, and total damage dealt. From domain knowledge, these variables inevitably increase as you keep playing in a match. I think I might need to change some columns to scale by time in minutes and then remove the time column. \nSo after dealing with the issue of time in the dataset, I think the ideal approach is to utilize the features to make a model that can predict an unseen match data to a specific rank. This would require me to split the dataset for training and testing. \nFor this Exploratory Data Analysis section, I will look into each numeric variable and categorical variables with mean and median to explain the overall trend from lowest to highest rank. For some variables I will also look into the standard deviation to see how varied the values are per rank."
  },
  {
    "objectID": "eda.html#quick-look-at-the-data",
    "href": "eda.html#quick-look-at-the-data",
    "title": "Data Exploration",
    "section": "Quick look at the data",
    "text": "Quick look at the data\n\n# Import seaborn\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Apply the default theme\nsns.set_theme(style=\"whitegrid\", palette=\"pastel\")\n\n# Load an example dataset\ntips = sns.load_dataset(\"tips\")\nprint(tips)\n\n     total_bill   tip     sex smoker   day    time  size\n0         16.99  1.01  Female     No   Sun  Dinner     2\n1         10.34  1.66    Male     No   Sun  Dinner     3\n2         21.01  3.50    Male     No   Sun  Dinner     3\n3         23.68  3.31    Male     No   Sun  Dinner     2\n4         24.59  3.61  Female     No   Sun  Dinner     4\n..          ...   ...     ...    ...   ...     ...   ...\n239       29.03  5.92    Male     No   Sat  Dinner     3\n240       27.18  2.00  Female    Yes   Sat  Dinner     2\n241       22.67  2.00    Male    Yes   Sat  Dinner     2\n242       17.82  1.75    Male     No   Sat  Dinner     2\n243       18.78  3.00  Female     No  Thur  Dinner     2\n\n[244 rows x 7 columns]"
  },
  {
    "objectID": "eda.html#basic-visualization",
    "href": "eda.html#basic-visualization",
    "title": "Data Exploration",
    "section": "Basic visualization",
    "text": "Basic visualization\n\n\n# Create a visualization\nsns.relplot(\n    data=tips,\n    x=\"total_bill\", y=\"tip\", col=\"time\",\n    hue=\"smoker\", style=\"smoker\", size=\"size\",\n)\n\nplt.show()"
  },
  {
    "objectID": "decision_tree.html",
    "href": "decision_tree.html",
    "title": "Decision Tree and Random Forest",
    "section": "",
    "text": "The code used to create my Baseline, a basic Decision Tree, and a Random Forest can be found here.\nThis was done on the Record data found here."
  },
  {
    "objectID": "data_cleaning.html",
    "href": "data_cleaning.html",
    "title": "Data Cleaning",
    "section": "",
    "text": "Link to source of cleaning data code (Python and R) on Github: Source Code\nLink to raw data on Github: Raw Data  The retrieval of this data was explained in “Data Gathering” tab.\nLink to cleaned data on Github: Cleaned Data"
  },
  {
    "objectID": "conclusion.html",
    "href": "conclusion.html",
    "title": "Conclusions",
    "section": "",
    "text": "League of Legends Image Source\n\n\nTo reiterate my project scope, I hope to do my investigation on the mainstream video game League of Legends. This was because of the limited amount of available data that I could retrieve relating to player data. And the reason I am looking specifically at player data is so that I can find variables within the game that might distinctly separate skill rating classes of players. So to find some underlying trends/information out of the data of thousands of players, I used different techniques listed below and took away some insights:\n\nNaive Bayes\nDimensionality Reduction\nClustering\nDecision Tree\nRandom Forest\n\n\n\nMy first venture was using Naive Bayes to build a model that could potentially classify the rank of a player given their unseen match data. This idea dives right into my project scope as I believed that certain differently ranked players are distinct enough in match data. After going through this technique, my resulting model (even after feature selection) had about a 20% accuracy. This had a lot of implications relating to my project idea. It meant that my dataset did not show a clear enough pattern between rank classes to accurately classify an unseen player’s rank based on their match data. This could mean many things from retrieving the insignificant features to this being an inherently impossible task. I think moving forward, I would work on building a different dataset that includes more variables to possibly find more significant features that might better predict a player’s rank.\nSomething exciting that I did find was that there were indeed features within the game that should be valued more when determining a player’s rank. This was found with feature selection.\nOn a separate mini-project relating to Naive Bayes, I looked into how related are the fictional characters (champions) being played by players correlate to their chosen position. I found in this mini-project that there does seem to be a consensus of what position certain champions play despite having no restrictions on where they can be played. The model created in this case performed very well and showed that there seems to be a community driven agreement of what positions certain champions play the best.\n\n\n\nI found the use of different dimensionality reduction in my project. Namely, the use of Principal Component Analysis (PCA) and t-Distributed Stochastic Neighbor Embedding (t-SNE). Here is what I found using each method:\nI found that using t-SNE might have helped more in understanding my dataset better. This was because of the ability to tune the perplexity of dimensionally reducing my dataset with t-SNE. This allowed me to see how the relationship of points changed with higher perplexity which uncovered more about the global relationship between points in my dataset. Using a lower perplexity showed a relatively insignificant distribution of points similar to what I saw with PCA.\nI felt my visualization with t-SNE and the comparison visualization with PCA showed that my dataset was a lot more complex than I originally anticipated. This further emphasized what I found in my Naive Bayes step, that my retrieved dataset of player match data might be inherently too complex or contains too much noise for a classification model.\n\n\n\nIn this clustering step, I basically looked how different clustering techniques might play a role in my player match data dataset. I found that, again, my dataset was inherently really complex which led to my model having a low 20% accuracy. This step further emphasized what I found before but it did lead me to believe that I am lacking more unique variables and that noise might play a bigger role than I thought. So if I were to continue with this project, I would look to include more features into my dataset and employ noise or outlier reducing techniques.\n\n\n\nIn this step, I built a basic decision tree after using a Scikit-Learn function called GridSearchCV that looked for the highest accuracy with different combinations of hyperparameters for the given decision tree model. What I found was a similar classification model accuracy compared to what I found in Naive Bayes.\nThis just further emphasized the issue with my dataset being too complex or containing too much noise.\n\n\n\nIn this final technique, I used a Random Forest Classification model to compare what I found in the basic Decision Tree model as well as my Naive Bayes model. I found again 20% accuracy as my model accuracy score after optimizing hyperparameters. In the end I found the same results as I found in my first technique, Naive Bayes."
  },
  {
    "objectID": "arm.html",
    "href": "arm.html",
    "title": "ARM",
    "section": "",
    "text": "Build out your website tab for ARM"
  },
  {
    "objectID": "about_me/about_me.html",
    "href": "about_me/about_me.html",
    "title": "About Me",
    "section": "",
    "text": "Shawn Xu, Boston University Graduation May 2023\n\n\nHello, I am Shawn Xu and I am currently a student in the M.S. Data Science and Analytics program at Georgetown University. Before attending Georgetown University, I received my Bachelor’s degree in Biomedical Engineering from Boston University where I focused mainly on biomedical lab research on proteins. A primary experience of mine was focused on the implications of protein degradation in the treatment of cancer. Now transitioning to Data Science, I hope to implement what I learned and will learn into my interests and hobbies.\n\nEducation:\n\n2025: M.S. Data Science and Analytics, Georgetown University\n2023: B.S. Biomedical Engineering, Boston University\n\n\n\nAcademic Interests:\n\nArtificial Intelligence, Machine Learning, and Deep Learning\nNatural Language Processing\nConvolution Neural Networks\nData Science in Public Health, Medicine, Biology, and Gaming\n\n\n\nContact Info:\n\nEmail: sx131@georgetown.edu"
  },
  {
    "objectID": "clustering.html",
    "href": "clustering.html",
    "title": "Clustering",
    "section": "",
    "text": "For this clustering section, I plan to use different clustering techniques for analysis of my record data that I retrieved from the Riot API. The data contains match data collected from a multitude of players from different ranks and the cleaned version of the data can be found here.  \nMy goal with clustering for my record data is to see if I can perform unsupervised clustering on data after removing the labels and then comparing the results to the original cluster distribution WITH labels. I want to see if my data is too confusing with the retrieved variables or is distinct enough per class label (rank). This might provide more insight on my results from Naive Bayes Classification.  \nK-Means Clustering code: link  DBSCAN Clustering code: link  Hierarchical Clustering code: link"
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "Data",
    "section": "",
    "text": "Access the Data through the project Github Repository.\n\nData Directory:\ndata/\n├── 01-raw-riot-data    (Raw retrieved player data from Riot API)\n│   ├── league-data     (Record Data of Each Rank Class)\n│   │   ├── league_bronze_data.csv\n│   │   ├── league_chall.csv\n│   │   ├── league_diamond_data.csv\n│   │   ├── league_emerald_data.csv\n│   │   ├── league_gold_chall.csv\n│   │   ├── league_iron_chall.csv\n│   │   ├── league_platinum_chall.csv\n│   │   └── league_silver_data.csv\n│   └── league-text-data    (Text Data of Each Rank Class)\n│       ├── bronze_text_data.csv\n│       ├── diamond_text_data.csv\n│       ├── emerald_text_data.csv\n│       ├── gold_text_data.csv\n│       ├── iron_text_data.csv\n│       ├── platinum_text_data.csv\n│       └── silver_silver_data.csv\n└── 02-cleaned_riot_data    (Combined/Cleaned Datasets)\n    ├── chall_data_cleaned.csv\n    ├── combined_text_data_cleaned.csv\n    ├── league_combined_cleaned.csv\n    ├── league_combined_with_chall_cleaned.csv\n    └── position_sum_cleaned.csv"
  },
  {
    "objectID": "data_gathering.html",
    "href": "data_gathering.html",
    "title": "Data Gathering",
    "section": "",
    "text": "Link to the source of retrieval code: Source Code\nLink to Riot’s APIs: Riot API"
  },
  {
    "objectID": "dim_red.html",
    "href": "dim_red.html",
    "title": "Dimensionality Reduction",
    "section": "",
    "text": "In this section of my project, I hope to utilize some Dimensionality reduction techniques on the data that I gathered from the Riot API to better suit the dataset for future modeling. As seen in the feature selection tab, I was able to find the most relevant variables to use for my Naive Bayes classification modeling. Using what I found from that venture, I hope to compare the feature selection results with results from using Dimensionality Reduction techniques, Principal Component Analysis (PCA) and t-Distributed Stochastic Neighbor Embedding (t-SNE), on the same dataset. After performing the techniques, I want to explore how the variance of the dataset changes through visualizations. This will help me compare the results of my feature selection results with the results from PCA and t-SNE.  \n\n\n\nDimensionality Reduction Image Source\n\n\nKey Libraries  I will be coding these techniques up on Python by using core functions from modules like Pandas, Numpy, and Scikit-Learn. General data management will come from Pandas and Numpy while the techniques for PCA and t-SNE will mainly come from the Scikit-Learn library. To create visualizations as mentioned in my outline above, I will use the matplotlib library to do this.  \nimport pandas as pd\nimport numpy as np\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE\nimport matplotlib.pyplot as plt\nHow does this relate to my project?  As an aspiring Data Scientist, I hope to go more into Machine Learning, Deep Learning, and AI which means these techniques should be explored somewhat in order to understand fundamental processes that were later advanced. And with my desire to work on statistical analysis of games, I hope to explore these techniques on my retrieved dataset from the Riot API in order to understand the practicality of these techniques under this topic."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Home Page",
    "section": "",
    "text": "Player Rank Analysis Final Project\n\n\n\nImage Source\n\n\nIn this website I will go through my project of investigating how certain players’ skill rating are determined based on in-game match data. Due to the limited amount of available player data for competitive video games, I will only examine the mainstream competitive video game: League of Legends.\n\nProject Organization\n\nIntroduction:\nFor the introduction I wanted to give some contextual information about me as well as the idea that I had for this Data Science project. This section contains in intro about me, an intro about my project, the data that I used, and the code that I made.\n\nAbout Me\nCode\nData\nIntroduction\n\n\n\nData Preparation:\nFor the Data Preparation section, I worked on retrieving textual and record data from the Riot API. More information can be found in the following tabs.\n\nData Gathering\nData Cleaning\nData Exploration\n\n\n\nTechniques:\nHere lists some of techniques that I used on my retrieved data. Namely, I used Naive Bayes classification, Dimensionality Reduction, Clustering, and some Decision Tree classification techniques.\n\nNaive Bayes\nDimensionality Reduction\nClustering\nDecision Trees\n\n\n\nConclusion:\nA small concluding segment where I talk about my findings and how it relates back to my project idea.\n\nConclusions"
  },
  {
    "objectID": "eda.html#data-understanding",
    "href": "eda.html#data-understanding",
    "title": "Data Exploration",
    "section": "",
    "text": "The general packages I used and setting the theme of graphs:\n\n\nCode\n# Import packages\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\n\n# Apply the default theme\nsns.set_theme(style=\"whitegrid\", palette=\"pastel\")\n\n\nLoading in the dataset to EDA:\n\n\nCode\n#Import both Challenger and all other ranks Datasets (combined dataset)\ncombined_league_ranks = pd.read_csv('../../data/cleaned_riot_data/league_combined_with_chall_cleaned.csv')\n\n#Print the first few rows of the dataset\nprint(combined_league_ranks.head())\n\n\n     win  kills  deaths  dmgObj  dmgTurr  vision_score  totalDmg  \\\n0   True      3       2    6298     6298            10    148123   \n1  False      7       5    3222      424            15    116804   \n2   True     16       1   12446     2012            13    110153   \n3   True     13       2   10605     4966             9    148142   \n4   True      1       2    1430     1075            25     14254   \n\n   totalDmgTaken  totalMinions   gold position       time  rank  \n0          24127           197  11108   middle  29.150000  iron  \n1          24526           144  12407   middle  29.916667  iron  \n2          12996           145  13989   middle  28.433333  iron  \n3          26504           192  14154   middle  26.516667  iron  \n4          10728            19   7288  utility  25.100000  iron  \n\n\n\n\nAfter briefly looking at the dataset that I collected and cleaned, I notice that there are many unique variables being used in the columns. Namely there are 13 variables that I can look into individually. From the dataset, I can tell that it is mostly numeric data with one float variable (time), two string variables (rank and position), and one Boolean column (win). The rest being numeric variables. For the sake of my later analysis with Naive Bayes, I will assume that these variables are independent. However, I believe there are some major correlation with these variables. One that sticks out to me is the time column with columns like gold earned, minions killed, and total damage dealt. From domain knowledge, these variables inevitably increase as you keep playing in a match. I think I might need to change some columns to scale by time in minutes and then remove the time column. \nSo after dealing with the issue of time in the dataset, I think the ideal approach is to utilize the features to make a model that can predict an unseen match data to a specific rank. This would require me to split the dataset for training and testing. \nFor this Exploratory Data Analysis section, I will look into each numeric variable and categorical variables with mean and median to explain the overall trend from lowest to highest rank. For some variables I will also look into the standard deviation to see how varied the values are per rank."
  },
  {
    "objectID": "eda.html#descriptive-statistics",
    "href": "eda.html#descriptive-statistics",
    "title": "Data Exploration",
    "section": "Descriptive Statistics:",
    "text": "Descriptive Statistics:\n\nFrequency of Each Rank in Dataset\n\n\nCode\n#Lets visualize some basic statistics:\n#Lets see the frequency of matches for each category of rank:\nrank_freq = combined_league_ranks['rank'].value_counts()\n#Bar graph plot it\n#Rank order from lowest to highest rank (left to right)\nrank_order = ['iron', 'bronze', 'silver', 'gold', 'platinum', 'emerald', 'diamond', 'challenger']\nrank_freq[rank_order].plot(kind='bar')\nplt.xlabel('League Ranks')\nplt.ylabel('Frequency')\nplt.title('Frequency of Each Class')\n\n\nText(0.5, 1.0, 'Frequency of Each Class')\n\n\n\n\n\nFrom this simple frequency bar plot of the categorical variable \"rank\", we can see that when I pulled about 200 players in each rank and got their 10 most recent matches that ranks from gold and above have a higher density of ranked games being played compared to lower ranks. One could thus infer that these ranked players prefer to play more ranked solo/duo queue games than lower ranks.\n\n\nFrequency of Position in the Dataset\n\n\nCode\n#Get the freq of each Position in Dataset\nposition_freq = combined_league_ranks['position'].value_counts()\n#Bar graph plot it\n#Rank order from lowest to highest rank (left to right)\nposition_freq.plot(kind='bar')\nplt.xlabel('Positions')\nplt.ylabel('Frequency')\nplt.title('Frequency of Each Position')\n\n\nText(0.5, 1.0, 'Frequency of Each Position')\n\n\n\n\n\nAcross all ranks in this dataset, this plot shows the overall frequency of each position played. Top lane is played the most followed by jungle, then middle lane, then bottom lane, and finally utility or support.\n\n\nMean and Median of Gold Earned Rate in Each Rank\n\n\nCode\n#First change gold column to rate earned per minute (time col)\ncombined_league_ranks['gold/min'] = combined_league_ranks['gold']/combined_league_ranks['time']\n\n#Group dataset by class then .agg() to get mean and median for gold variable\ngold_mean_med_df = combined_league_ranks.groupby('rank')['gold/min'].agg(['mean', 'median']).reindex(rank_order).reset_index()\n\n#Now plot together in one plot\nfig, ax = plt.subplots()\n#mean plot\ngold_mean_med_df.plot(kind='bar', x='rank', y='mean', ax=ax, position=0, width=0.4, color='blue', label='Mean', alpha=0.4)\n#median plot\ngold_mean_med_df.plot(kind='bar', x='rank', y='median', ax=ax, position=0, width=0.4, color='red', label='Median', alpha=0.4)\n#labels, legend, title\nplt.xlabel('Ranks')\nplt.ylabel('Gold/min')\nplt.title('Mean and Median of Gold Earned per Minute for Each Rank')\nplt.legend()\nplt.show()\n\n\n\n\n\nFirstly, the Mean (blue) and Median (red) are generally very close together as seen in the plot as most of it is purple (blue overlapping with the red). Next, in this simple plot we can see that as you move up in rank that the players are more efficient at obtaining gold as the rate (gold earned per minute) noticeably goes up as you examine higher ranks.\n\n\nMean and Median of Total Damage Rate in Each Rank\n\n\nCode\n#Follow the same exact pattern as gold earned per minute but for total damage dealt\ncombined_league_ranks['totalDmg/min'] = combined_league_ranks['totalDmg']/combined_league_ranks['time']\n\n#Group dataset by class then .agg() to get mean and median\ntotalDmg_mean_med_df = combined_league_ranks.groupby('rank')['totalDmg/min'].agg(['mean', 'median']).reindex(rank_order).reset_index()\n\n#Now plot together in one plot\nfig, ax = plt.subplots()\n#mean plot\ntotalDmg_mean_med_df.plot(kind='bar', x='rank', y='mean', ax=ax, position=0, width=0.4, color='blue', label='Mean', alpha=0.4)\n#median plot\ntotalDmg_mean_med_df.plot(kind='bar', x='rank', y='median', ax=ax, position=0, width=0.4, color='red', label='Median', alpha=0.4)\n#labels, legend, title\nplt.xlabel('Ranks')\nplt.ylabel('totalDmg/min')\nplt.title('Mean and Median of Total Damage dealt per Minute for Each Rank')\nplt.legend()\nplt.show()\n\n\n\n\n\nSimilar to the gold earned per minute, there is general upward trend of total damage dealt per minute as the rank goes up.\n\n\nMean and Median of Player Kill Rate in Each Rank\n\n\nCode\n#Follow the same exact pattern as gold earned per minute but for total player kills\ncombined_league_ranks['kills/min'] = combined_league_ranks['kills']/combined_league_ranks['time']\n\n#Group dataset by class then .agg() to get mean and median\nkill_mean_med_df = combined_league_ranks.groupby('rank')['kills/min'].agg(['mean', 'median']).reindex(rank_order).reset_index()\n\n#Now plot together in one plot\nfig, ax = plt.subplots()\n#mean plot\nkill_mean_med_df.plot(kind='bar', x='rank', y='mean', ax=ax, position=0, width=0.4, color='blue', label='Mean', alpha=0.4)\n#median plot\nkill_mean_med_df.plot(kind='bar', x='rank', y='median', ax=ax, position=0, width=0.4, color='red', label='Median', alpha=0.4)\n#labels, legend, title\nplt.xlabel('Ranks')\nplt.ylabel('kill/min')\nplt.title('Mean and Median of Player kills per Minute for Each Rank')\nplt.legend()\nplt.show()\n\n\n\n\n\nThis has a generally less obvious trend. Player kill rate per minute seems to be consistent across ranks from bronze and up. Iron players have noticeably less kills/min and, actually, Challenger players surprisingly have somewhat less kills/min as well than the middle ranks.\n\n\nMean and Median of Player Death Rate in Each Rank\n\n\nCode\n#Follow the same exact pattern as gold earned per minute but for total player deaths\ncombined_league_ranks['deaths/min'] = combined_league_ranks['deaths']/combined_league_ranks['time']\n\n#Group dataset by class then .agg() to get mean and median\ndeath_mean_med_df = combined_league_ranks.groupby('rank')['deaths/min'].agg(['mean', 'median']).reindex(rank_order).reset_index()\n\n#Now plot together in one plot\nfig, ax = plt.subplots()\n#mean plot\ndeath_mean_med_df.plot(kind='bar', x='rank', y='mean', ax=ax, position=0, width=0.4, color='blue', label='Mean', alpha=0.4)\n#median plot\ndeath_mean_med_df.plot(kind='bar', x='rank', y='median', ax=ax, position=0, width=0.4, color='red', label='Median', alpha=0.4)\n#labels, legend, title\nplt.xlabel('Ranks')\nplt.ylabel('deaths/min')\nplt.title('Mean and Median of Player Deaths per Minute for Each Rank')\nplt.legend()\nplt.show()\n\n\n\n\n\nFor player deaths per minute, the rate seems pretty consistent across all ranks. Though it does seem a tiny bit higher in the lower ranks compared the the higher ranks like Challenger and Diamond. This could mean that players are more careful to not die throughout the game.\n\n\nMean and Median of Damage to Objectives Dealt Rate in Each Rank\n\n\nCode\n#Follow the same exact pattern as gold earned per minute but for total dmg dealt to objectives\ncombined_league_ranks['dmgObj/min'] = combined_league_ranks['dmgObj']/combined_league_ranks['time']\n\n#Group dataset by class then .agg() to get mean and median\ndmgObj_mean_med_df = combined_league_ranks.groupby('rank')['dmgObj/min'].agg(['mean', 'median']).reindex(rank_order).reset_index()\n\n#Now plot together in one plot\nfig, ax = plt.subplots()\n#mean plot\ndmgObj_mean_med_df.plot(kind='bar', x='rank', y='mean', ax=ax, position=0, width=0.4, color='blue', label='Mean', alpha=0.4)\n#median plot\ndmgObj_mean_med_df.plot(kind='bar', x='rank', y='median', ax=ax, position=0, width=0.4, color='red', label='Median', alpha=0.4)\n#labels, legend, title\nplt.xlabel('Ranks')\nplt.ylabel('dmgObj/min')\nplt.title('Mean and Median of Damage Dealt to Objectives per Minute for Each Rank')\nplt.legend()\nplt.show()\n\n\n\n\n\nThe rate for this variable seems to vary a lot across all ranks. This could be a variable that is useful in classifying a rank on unseen data.  Overall though, the trend follows an upward trend like for gold earned where higher ranks damage objectives more or more efficiently.\n\n\nMean and Median of Damage to Turrets Dealt Rate in Each Rank\n\n\nCode\n#Follow the same exact pattern as gold earned per minute but for total dmg dealt to turrets\ncombined_league_ranks['dmgTurr/min'] = combined_league_ranks['dmgTurr']/combined_league_ranks['time']\n\n#Group dataset by class then .agg() to get mean and median\ndmgTurr_mean_med_df = combined_league_ranks.groupby('rank')['dmgTurr/min'].agg(['mean', 'median']).reindex(rank_order).reset_index()\n\n#Now plot together in one plot\nfig, ax = plt.subplots()\n#mean plot\ndmgTurr_mean_med_df.plot(kind='bar', x='rank', y='mean', ax=ax, position=0, width=0.4, color='blue', label='Mean', alpha=0.4)\n#median plot\ndmgTurr_mean_med_df.plot(kind='bar', x='rank', y='median', ax=ax, position=0, width=0.4, color='red', label='Median', alpha=0.4)\n#labels, legend, title\nplt.xlabel('Ranks')\nplt.ylabel('dmgTurr/min')\nplt.title('Mean and Median of Damage Dealt to Turrets per Minute for Each Rank')\nplt.legend()\nplt.show()\n\n\n\n\n\nThis is similarly varied like Objective damage. This could also be a feature that is important in predicting rank. This also shows higher ranks doing more damage to turrets but Challenger players unexpectedly do less than the middle ranks. Sieging enemy turrets might not matter as well among the highest level of players?\n\n\nMean and Median of Vision Score Rate in Each Rank\n\n\nCode\n#Follow the same exact pattern as gold earned per minute but for vision score\ncombined_league_ranks['vision_score/min'] = combined_league_ranks['vision_score']/combined_league_ranks['time']\n\n#Group dataset by class then .agg() to get mean and median\nvision_score_mean_med_df = combined_league_ranks.groupby('rank')['vision_score/min'].agg(['mean', 'median']).reindex(rank_order).reset_index()\n\n#Now plot together in one plot\nfig, ax = plt.subplots()\n#mean plot\nvision_score_mean_med_df.plot(kind='bar', x='rank', y='mean', ax=ax, position=0, width=0.4, color='blue', label='Mean', alpha=0.4)\n#median plot\nvision_score_mean_med_df.plot(kind='bar', x='rank', y='median', ax=ax, position=0, width=0.4, color='red', label='Median', alpha=0.4)\n#labels, legend, title\nplt.xlabel('Ranks')\nplt.ylabel('vision_score/min')\nplt.title('Mean and Median of Vision Score per Minute for Each Rank')\nplt.legend()\nplt.show()\n\n\n\n\n\nVision score across the map is an important role for every player as it means control over the information across the entire map. The variation between median and mean is higher for vision score than variables like gold earned and total damage dealt which could be related to the different positions players play as recorded in the dataset. In general though, there is higher vision score as you go higher up in rank. Bronze rank is somewhat an outlier though.\n\n\nMean and Median of Total Damage Taken Rate in Each Rank\n\n\nCode\n#Follow the same exact pattern as gold earned per minute but for damage taken\ncombined_league_ranks['totalDmgTaken/min'] = combined_league_ranks['totalDmgTaken']/combined_league_ranks['time']\n\n#Group dataset by class then .agg() to get mean and median\ntotalDmgTaken_mean_med_df = combined_league_ranks.groupby('rank')['totalDmgTaken/min'].agg(['mean', 'median']).reindex(rank_order).reset_index()\n\n#Now plot together in one plot\nfig, ax = plt.subplots()\n#mean plot\ntotalDmgTaken_mean_med_df.plot(kind='bar', x='rank', y='mean', ax=ax, position=0, width=0.4, color='blue', label='Mean', alpha=0.4)\n#median plot\ntotalDmgTaken_mean_med_df.plot(kind='bar', x='rank', y='median', ax=ax, position=0, width=0.4, color='red', label='Median', alpha=0.4)\n#labels, legend, title\nplt.xlabel('Ranks')\nplt.ylabel('totalDmgTaken/min')\nplt.title('Mean and Median of Total Damage Taken per Minute for Each Rank')\nplt.legend()\nplt.show()\n\n\n\n\n\nThe trend of total damage dealt might be related to total damage taken. With lower damage dealt that also means lower damage taken. Logically, a better rated player would be able to deal more damage while taking minimal damage. The lowest rank Iron had the lowest damage dealt which means a low total damage taken might have some correlation to that variable. Otherwise, this variable seems consistent across the other ranks except Challenger which also shows a lower value.\n\n\nMean and Median of Total Minions Farmed Rate in Each Rank\n\n\nCode\n#Follow the same exact pattern as gold earned per minute but for total minions farmed\ncombined_league_ranks['totalMinions/min'] = combined_league_ranks['totalMinions']/combined_league_ranks['time']\n\n#Group dataset by class then .agg() to get mean and median\ntotalMinions_mean_med_df = combined_league_ranks.groupby('rank')['totalMinions/min'].agg(['mean', 'median']).reindex(rank_order).reset_index()\n\n#Now plot together in one plot\nfig, ax = plt.subplots()\n#mean plot\ntotalMinions_mean_med_df.plot(kind='bar', x='rank', y='mean', ax=ax, position=0, width=0.4, color='blue', label='Mean', alpha=0.4)\n#median plot\ntotalMinions_mean_med_df.plot(kind='bar', x='rank', y='median', ax=ax, position=0, width=0.4, color='red', label='Median', alpha=0.4)\n#labels, legend, title\nplt.xlabel('Ranks')\nplt.ylabel('totalMinions/min')\nplt.title('Mean and Median of Total Minions Farmed per Minute for Each Rank')\nplt.legend()\nplt.show()\n\n\n\n\n\nMinions are the number of entity mobs in the game that appear in waves occasionally going down 3 lanes. These entities are a big source of gold for players. To have the ability of farming these entities efficiently throughout the game can determine how strong a player is at every time point. For the first time, the medians for ranks Silver and above have higher medians than means. This could be related to how the role \"utility\" tends to not farm for gold but focuses on vision or support fighting."
  },
  {
    "objectID": "eda.html#data-visualizations",
    "href": "eda.html#data-visualizations",
    "title": "Data Exploration",
    "section": "Data Visualizations",
    "text": "Data Visualizations\n\nPossible Relationship: Total Damage Dealt vs Total Damage Taken\n\n\nCode\n#scatterplot generation for totalDmg/min (x-axis) vs totalDmgTaken/min (y-axis) variables\nsns.scatterplot(x=combined_league_ranks['totalDmg/min'], y=combined_league_ranks['totalDmgTaken/min'], hue=combined_league_ranks['rank'], alpha=0.7)\nplt.title(\"Correlation Plot of TotalDmg/min vs TotalDmgTaken/min\")\nplt.xlabel(\"totalDmg/min\")\nplt.ylabel(\"totalDmgTaken/min\")\nplt.show()\n\n\n\n\n\nThe scatterplot seems to show some sort of relationship between the variables and so I will try a regression line for each rank to clarify…\n\n\nCode\n#Now do regression line for the same variables as above ^\nsns.lmplot(data=combined_league_ranks, x='totalDmg/min', y='totalDmgTaken/min', hue='rank', scatter=False)  # Add regression line\n\nplt.title('Regression Lines Colored by Rank of Total Dmg Dealt/min vs Total Damage Taken/min')\nplt.xlabel('totalDmg/min')\nplt.ylabel('totalDmgTaken/min')\nplt.show()\n\n\nc:\\Users\\xusha\\anaconda3\\envs\\dsan5000\\Lib\\site-packages\\seaborn\\axisgrid.py:118: UserWarning: The figure layout has changed to tight\n  self._figure.tight_layout(*args, **kwargs)\n\n\n\n\n\nVariation of the regression lines for each rank appears to increase at the beginning and towards the end. However, the correlation of the two variables (total damage dealt per minute versus total damage taken per minute) does seem to vary less towards the middle-ish of the line. Additionally these lines seemingly cross at where the variation of the line is somewhat at a minimum for each rank shown in the plot. This is significant because it kinda tells us that this correlation might be found similarly across all ranks. Finally, the lines each have a positive slope which adds evidence to the correlation between the two variables of 'totalDmg/min' and 'totalDmgTaken/min'.\n\n\nPossible Relationship: Gold Earned versus Deaths\n\n\nCode\n#scatterplot generation for gold/min (x-axis) vs deaths/min (y-axis) variables\nsns.scatterplot(x=combined_league_ranks['gold/min'], y=combined_league_ranks['deaths/min'], hue=combined_league_ranks['rank'], alpha=0.7)\nplt.title(\"Correlation Plot of gold/min vs deaths/min\")\nplt.xlabel(\"gold/min\")\nplt.ylabel(\"deaths/min\")\nplt.show()\n\n#now do a regression line for the data points for gold/min vs deaths/min\nsns.lmplot(data=combined_league_ranks, x='gold/min', y='deaths/min', hue='rank', scatter=False)  # Add regression line\n\nplt.title('Regression Lines Colored by Rank')\nplt.xlabel('gold/min')\nplt.ylabel('deaths/min')\nplt.show()\n\n\n\n\n\nc:\\Users\\xusha\\anaconda3\\envs\\dsan5000\\Lib\\site-packages\\seaborn\\axisgrid.py:118: UserWarning: The figure layout has changed to tight\n  self._figure.tight_layout(*args, **kwargs)\n\n\n\n\n\nAlthough it was a long-shot, I wanted to explore whether the relationship between the amount of gold earned per minute for a player in each rank and number of player deaths per minute existed. My thought process was that after a player’s character dies in the match, they lose out on opportunities of getting gold and experience points from either farming minions or fighting enemy players, etc. So hypothetically the more a player dies would mean they have a lower gold earned per minute value. From the plot, the negative slope correlation does support my theory as having a higher deaths per minute rate then they would have less gold earned per minute. Though, there are massive variations throughout the lines plotted which could be attributed to how inconsistent this relationship is and also how varied the variables are per rank. As we have seen before, the amount of gold earned per minute does seem to increase as you go higher in rank but the amount of deaths per minute seems to be consistent throughout all ranks. The lack of uniqueness of deaths per minute by rank might be a reason the variation of the regression lines are so high for each rank.\n\n\nConfusion Matrix Heatmap of Variables per Time\n\n\nCode\n#subset the dataframe of all variables that scale with time (9 variables)\nleague_ranks_selected = combined_league_ranks[['gold/min','totalDmg/min','kills/min','deaths/min','dmgObj/min','dmgTurr/min','vision_score/min','totalDmgTaken/min','totalMinions/min']]\nprint(league_ranks_selected.head())\n\n\n     gold/min  totalDmg/min  kills/min  deaths/min  dmgObj/min  dmgTurr/min  \\\n0  381.063465   5081.406518   0.102916    0.068611  216.054889   216.054889   \n1  414.718663   3904.311978   0.233983    0.167131  107.699164    14.172702   \n2  491.992966   3874.079719   0.562720    0.035170  437.725674    70.762016   \n3  533.777498   5586.750471   0.490258    0.075424  399.937146   187.278441   \n4  290.358566    567.888446   0.039841    0.079681   56.972112    42.828685   \n\n   vision_score/min  totalDmgTaken/min  totalMinions/min  \n0          0.343053         827.684391          6.758148  \n1          0.501393         819.810585          4.813370  \n2          0.457210         457.069168          5.099648  \n3          0.339409         999.522313          7.240729  \n4          0.996016         427.410359          0.756972  \n\n\n\n\nCode\n#find correlation of each of the selected variables\nleague_var_heatmap = league_ranks_selected.corr()\n#then put each variable with each other including itself on a heatmap\nsns.heatmap(league_var_heatmap, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\n\n\n&lt;Axes: &gt;\n\n\n\n\n\nWe can see in this heatmap how each variable correlates with each other to summarize all variables quickly in one heatmap. In this confusion matrix, we can verify what I found earlier with Damage Dealt vs Damage Taken and Total gold earned vs Total deaths. We can see that these correlations do seem to appear again where deaths/min and gold/min is somewhat negatively correlated (-0.21) and damage dealt/min and damage taken/min has a significant correlation (+0.50).  Overall, two variables stick out from the heatmap. According to the matrix, the vision score per minute variable and player deaths per minute seem to the negatively correlate with all other variables. The only positive correlation among the mentioned variables is with deaths per minute versus total damage taken per minute which makes sense as dying more times means higher amount of damage being taken (more damage taken means more ways of reaching 0 health points or hp). These ideas are relatively understandable as placing and clearing vision on the map as well as dying within the match takes away time from gaining gold, dealing damage, or fighting other players. All other variables seem to be mostly positve correlated with each other except with the mentioned variables that show negative correlations.  Some interesting variables that include a decent mix of positive and negative correlations are minions farmed per minute and damage taken per minute. These variables could thus be analyzed further as these variables show some unique changes in correlations based on different variables within a match."
  },
  {
    "objectID": "eda.html#hypothesis-refining",
    "href": "eda.html#hypothesis-refining",
    "title": "Data Exploration",
    "section": "Hypothesis Refining",
    "text": "Hypothesis Refining\nFrom my exploration of the dataset that I will be using for my project, I have a much better understanding of what each variable defines and how each variable actually correlates with each other.  To understand how to enhance skill based matchmaking systems for competitive video games, it is important to understand how each variable in the game changes and affects each other within a match. And for our example competitive video game League of Legends that we explored we can see that there are variables that might need to be removed or included into other variables.  New Research Questions to Focus On:\n\nWhat variables, as seen in League of Legends, are most important in impacting predictive power of unseen data?\nAre these features what determine a player’s rank the best then?\nAre there any overlapping features in League of Legends that other competitive video games have and are these features impactful in predicting a player’s rank?"
  },
  {
    "objectID": "eda.html#data-grouping-and-segmentation-of-emerald-rank",
    "href": "eda.html#data-grouping-and-segmentation-of-emerald-rank",
    "title": "Data Exploration",
    "section": "Data Grouping and Segmentation of Emerald Rank",
    "text": "Data Grouping and Segmentation of Emerald Rank\nAcross all ranks in all the variables being briefly explored, I can see that the rank Platinum is almost always the middle of pack. They follow trends that correlate to rank and is always found to have the middle values. So, in this section I plan on looking into the variables that I think are significant in determining a player’s skill (gold earned, total damage dealt to objectives, total damage dealt to turrets, and vision score) for the Platinum rank in the dataset.  The point in this section is to see which subclass (or position) for a player is more relevant for my future prediction model. From domain knowledge, one can recognize the Utility role as an outlier of sorts as their match data will significantly differ from the rest of the players. This will be most apparent in gold earned which I will try to confirm as well.\n\nExamining Features in Platinum Rank for Position Subclasses\n\n#first subset the original dataset with just rank == 'platinum'\nplat_index = combined_league_ranks['rank'] == 'platinum'\nplat_match_data = combined_league_ranks[plat_index]\n\n#group by position then create bar plot of the mean and median of\n#three variables: gold/min, dmgObj/min, dmgTurr/min, and vision_score/min\nplat_agg_df = plat_match_data.groupby('position').agg({'gold/min': ['mean', 'median'],\n                                   'dmgObj/min': ['mean', 'median'],\n                                   'dmgTurr/min': ['mean', 'median'],\n                                   'vision_score/min': ['mean', 'median']})\nagg_df = plat_agg_df.reset_index()\n\n#configure plot\nbar_width = 0.2\nindex = np.arange(len(agg_df['position']))\n\nplt.figure(figsize=(12, 8))\n\n# plot the bars for mean\nplt.bar(index - 3*bar_width/2, agg_df['gold/min']['mean'], bar_width, label='Mean of Gold/min')\nplt.bar(index - bar_width/2, agg_df['dmgObj/min']['mean'], bar_width, label='Mean of dmgObj/min')\nplt.bar(index + bar_width/2, agg_df['dmgTurr/min']['mean'], bar_width, label='Mean of dmgTurr/min')\nplt.bar(index + 3*bar_width/2, agg_df['vision_score/min']['mean'], bar_width, label='Mean of vision score/min')\n\n# plot the bars for median\nplt.bar(index - 3*bar_width/2, agg_df['gold/min']['median'], bar_width, label='Median of Gold/min', alpha=0.5, hatch='/')\nplt.bar(index - bar_width/2, agg_df['dmgObj/min']['median'], bar_width, label='Median of dmgObj/min', alpha=0.5, hatch='/')\nplt.bar(index + bar_width/2, agg_df['dmgTurr/min']['median'], bar_width, label='Median of dmgTurr/min', alpha=0.5, hatch='/')\nplt.bar(index + 3*bar_width/2, agg_df['vision_score/min']['median'], bar_width, label='Median of vision score/min', alpha=0.5, hatch='/')\n\nplt.title('Mean and Median Values by Class')\nplt.xlabel('Class')\nplt.ylabel('Values')\nplt.legend()\nplt.xticks(index, agg_df['position'])\nplt.show()"
  },
  {
    "objectID": "eda.html#data-grouping-and-segmentation-of-platinum-rank",
    "href": "eda.html#data-grouping-and-segmentation-of-platinum-rank",
    "title": "Data Exploration",
    "section": "Data Grouping and Segmentation of Platinum Rank",
    "text": "Data Grouping and Segmentation of Platinum Rank\nAcross all ranks in all the variables being briefly explored, I can see that the rank Platinum is almost always the middle of pack. They follow trends that correlate to rank and is always found to have the middle values. So, in this section I plan on looking into the variables that I think are significant in determining a player’s skill (gold earned, total damage dealt to objectives, and total damage dealt to turrets) for the Platinum rank in the dataset.  The point in this section is to see which subclass (or position) for a player is more relevant for my future prediction model. From domain knowledge, one can recognize the Utility role as an outlier of sorts as their match data will significantly differ from the rest of the players. This will be most apparent in gold earned which I will try to confirm as well.\n\nExamining Features in Platinum Rank for Position Subclasses\n\n\nCode\n#first subset the original dataset with just rank == 'platinum'\nplat_index = combined_league_ranks['rank'] == 'platinum'\nplat_match_data = combined_league_ranks[plat_index]\n\n#group by position then create bar plot of the mean and median of\n#three variables: gold/min, dmgObj/min, dmgTurr/min, and vision_score/min\nplat_agg_df = plat_match_data.groupby('position').agg({'gold/min': ['mean', 'median'],\n                                   'dmgObj/min': ['mean', 'median'],\n                                   'dmgTurr/min': ['mean', 'median']})\nagg_df = plat_agg_df.reset_index()\n\n#configure plot\nbar_width = 0.2\nindex = np.arange(len(agg_df['position']))\n\nplt.figure(figsize=(12, 8))\n\n# plot the bars for mean\nplt.bar(index - 3*bar_width/2, agg_df['gold/min']['mean'], bar_width, label='Mean of Gold/min')\nplt.bar(index - bar_width/2, agg_df['dmgObj/min']['mean'], bar_width, label='Mean of dmgObj/min')\nplt.bar(index + bar_width/2, agg_df['dmgTurr/min']['mean'], bar_width, label='Mean of dmgTurr/min')\n\n\n# plot the bars for median\nplt.bar(index - 3*bar_width/2, agg_df['gold/min']['median'], bar_width, label='Median of Gold/min', alpha=0.5, hatch='/')\nplt.bar(index - bar_width/2, agg_df['dmgObj/min']['median'], bar_width, label='Median of dmgObj/min', alpha=0.5, hatch='/')\nplt.bar(index + bar_width/2, agg_df['dmgTurr/min']['median'], bar_width, label='Median of dmgTurr/min', alpha=0.5, hatch='/')\n\n\nplt.title('Mean and Median Values by Position in Platinum Rank')\nplt.xlabel('Positions')\nplt.ylabel('Specific Rates (gold/min, dmgObj/min, dmgTurr/min)')\nplt.legend()\nplt.xticks(index, agg_df['position'])\nplt.show()\n\n\n\n\n\nWe see that almost across all roles, that the amount of gold obtains is consistent except for Utility role. Also, the damage done to objectives per minute is significantly larger for the jungle position. So, if I were to specifically look into consistent roles for some average player then I would only look into bottom, middle, and top lanes as they have the most similar gold earned per minute, damage dealt to objectives per minute, and damage dealt to turrets per minute. \nNow in this plot, we can see that utility is a significantly different role in terms of these variables. They have less gold than all other positions and even less damage dealt overall to turrets and objectives alike. So moving forward, utility as position should not be included as it is an outlier class.  In a separate project, I could possibly also use these variations with the lanes to jungle or utility to predict what position a player was in some match given their match data.\n\n\nOutliers\nFrom the Data grouping and segmentation, I looked into the subclasses of a specific rank: Platinum. This was because that rank was in the middle of the pack across almost all variables in the dataset. Thus, I decided to look into the subclasses \"position\" of the rank Platinum to discover any out of the ordinary subclasses that I might have to remove. \nFrom the data grouping section, I learned that the “utility” position showed irregular values compared to the usual gold earned as well as damage dealt to turrets and damage dealt to objectives. So this subclass would thus be considered an outlier as this could hinder the quality of the prediction model that I will do later. \nAnother anomaly that should be addressed is how inflated the damage dealt to objectives is for position \"jungle\". This makes sense as that role has the most interaction with objectives. The issue is that its so significantly high that the average damage dealt on objectives for ranks that contain more \"jungle\" positions will have higher values. This is an issue that targets the integrity of the consistency for the prediction model. So I will also ignore the subclass “jungle” in my prediction model."
  },
  {
    "objectID": "eda.html#reportdiscuss-methods-and-findings",
    "href": "eda.html#reportdiscuss-methods-and-findings",
    "title": "Data Exploration",
    "section": "Report/Discuss Methods and Findings",
    "text": "Report/Discuss Methods and Findings\nSo from the overall findings from my EDA process, I realized that the variables that I collected from the Riot API contains multiple variables that seem both significant and insignificant. Namely, the deaths variable seems to be a consistent constant across all ranks meaning that the use of that variable might not prove useful. Other variables sometimes also correlate significantly well with each other like Total Damage Dealt per minute versus Total Damage Taken per minute so I will have to investigate these sorts of correlations more with feature selection.  Something else that should be addressed is the use of subclasses \"utility\" and \"jungle\". They contain somewhat outlier-like values that would hurt my prediction model in the future. These roles are unique and are thus special playstyles. To include them when the majority of the other roles consistently match would hinder the overall calculation of rank benchmarks for prediction."
  },
  {
    "objectID": "eda.html#tools-and-software",
    "href": "eda.html#tools-and-software",
    "title": "Data Exploration",
    "section": "Tools and Software",
    "text": "Tools and Software\nI plan on working with Naive Bayes as well as working with matrices/dataframes. I also will work with making visualizations. Thus, the packages that I will work with will be but not limited to: Pandas, Numpy, Scikit-learn, Seaborn, Matplotlib, and R to name a few."
  },
  {
    "objectID": "naive_bayes.html",
    "href": "naive_bayes.html",
    "title": "Naive Bayes",
    "section": "",
    "text": "Objective To develop a model that can predict unseen data to some classification is the primary purpose of Naive Bayes Classification. So to reach this objective of making a model that can accurately predict some class given sample data, this process would then employ multiple statistical concepts. \nFoundational Knowledge Naive Bayes requires the use of Bayes’ Theorem which is a probability concept that illustrates the probability of some situation, hypothesis, or case occurring based on prior understandings (prior probabilities). Thus, Naive Bayes is grounded in training probabilities from frequencies of features for the purpose of classification predictions.  In Naive Bayes, for it to be “naive” means that the features/variables being used for the classification prediction are independent of other variables.\n\n\n\nBayes Theorem Image Source\n\n\n\nSteps The concept of Naive Bayes employs prior probabilities, the likelihood of data collected per class label, output a posterior probability for each class, and finally assign the input with a class label with the highest posterior probability. \nThe Aim of Naive Bayes in this Project As mentioned before, in order to find ways of enhancing competitive video games’ skill-based matchmaking systems there needs to be analysis of how certain variables within a game determines one rank. So to do this, I aim to use Naive Bayes to create a prediction model that will output a prediction for data inputs. By using the collected values of variables from ranked players and their associated ranks as class labels, I have everything I need to utilize Naive Bayes in building a classification algorithm that will predict some unseen player data’s rank.  This will require me to first train my model with my dataset and then later be tested with unseen data. \n\n\n\nNaive Bayes Image Source\n\n\nDifferent Variants of Naive Bayes\n\nGaussian Naive Bayes: This is when the features are continuous and the values follow a Gaussian Distribution. Since it assumes features for each class are Gaussian distributed, then within each class they would find the mean and standard deviation for each feature for classification.\nMultinomial Naive Bayes: This time the features are assumed to follow a multinomial distribution. This type of Naive Bayes is pretty common with text data that utilize word counts for text classification.\nBernoulli Naive Bayes: Since Bernoulli is about some outcome being one or the other, this type of Naive Bayes assumes features are binary meaning the values could be one of two options: Present or Absent, 1 or 0, True or False."
  },
  {
    "objectID": "clustering.html#footnotes",
    "href": "clustering.html#footnotes",
    "title": "Clustering",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nhttps://optimaldesign.com/Download/ArrayMiner/AMatMETMBS2001.pdf↩︎\nhttps://ieeexplore.ieee.org/abstract/document/9038535?casa_token=gA0AHEO7pRsAAAAA:cE0uJNn7uZihBu-cEejdvFOf_-uxq1EUzDZA94x8C-EduMK-rBrez8rwa0NzuO9ozJmKh8tBcQ↩︎\nhttps://ieeexplore.ieee.org/abstract/document/6814687?casa_token=1IBA78BBBEwAAAAA:9G4vbIXhVSFPhzolMwHIhmpkVq4PKKLahjh4zyhglDg33TMQ1SSaJ4OM5ctx0Lyt8MjNMvOkeQ↩︎\nhttps://wires.onlinelibrary.wiley.com/doi/full/10.1002/widm.53?casa_token=iHd4jYEMyx0AAAAA%3Aa5hGgRtHnp0Cqbhh9b6T5pDTF4153N4PcqHT2eyA2A55Jokb6Jfn7GZbNiV73RMFx9HLrTw0BapXjik↩︎\nhttps://link.springer.com/chapter/10.1007/978-3-319-21903-5_8↩︎\nhttps://onlinelibrary.wiley.com/doi/full/10.1111/biom.12647?casa_token=wk0Kvbx__LYAAAAA%3AcIj7DX7EvzLPRrEEfNpOaEwEN8T2VV9uAv3oLjN2f5xzyqlJ1kzyrfsFTIAhCzUPcEANBo5NznkhM9Y↩︎"
  },
  {
    "objectID": "home.html",
    "href": "home.html",
    "title": "Enhancing Skill Based Matchmaking of Competitive Video Games",
    "section": "",
    "text": "Build out your website tab for ARM"
  },
  {
    "objectID": "index.html#skill-based-matchmaking-of-competitive-video-games",
    "href": "index.html#skill-based-matchmaking-of-competitive-video-games",
    "title": "Home Page",
    "section": "",
    "text": "Image Source"
  },
  {
    "objectID": "code.html",
    "href": "code.html",
    "title": "Code",
    "section": "",
    "text": "Access the code through Github Repository. \n\nCode Directory:\nHere is the structure of my code directory containing all the code for retrieving data, cleaning data, and analyses.\ncodes/\n├── 01-data-gathering       (Code for retrieving data)\n├── 02-data-cleaning        (Code for cleaning the data)\n├── 03-feature-selection    (Code for Feature Selection)\n├── 04-naive-bayes          (Code for Naive Bayes)\n├── 05-dim-red              (Code for Dimensional Reduction)\n├── 06-clustering           (Code for Clustering)\n└── 07-trees                (Code for different Tree Techniques)"
  },
  {
    "objectID": "introduction.html#some-questions-i-plan-on-investigating",
    "href": "introduction.html#some-questions-i-plan-on-investigating",
    "title": "Introduction",
    "section": "Some questions I plan on Investigating:",
    "text": "Some questions I plan on Investigating:\n\nWhat are the current SBMM algorithms being used right now in popular competitive games?\nHow do they determine a player’s skill?\nWhat performance metrics should I investigate?\nDo these metrics differ from game to game?\nHow are these metrics weighed and transformed into rating?\nHow are certain roles determined in games by metrics?\nHow do you weigh each role in skill rating?\nHow does the amount of games played affect skill rating gain?\nMore games with same skill rating = gain less rating?\nCan we still use outcome based systems like Elo?\nHow do you determine if a SBMM system is good?\nWhat API’s are available?\nAre there overlaps in metrics that can be used across different genres of games?"
  },
  {
    "objectID": "introduction.html#data-science-questions",
    "href": "introduction.html#data-science-questions",
    "title": "Introduction",
    "section": "Data Science Questions:",
    "text": "Data Science Questions:\n\nWhat are the current SBMM algorithms being used right now in popular competitive games?\nHow do they determine a player’s skill?\nWhat performance metrics should I investigate?\nDo these metrics differ from game to game?\nHow are these metrics weighed and transformed into rating?\nHow are certain roles determined in games by metrics?\nHow do you weigh each role in skill rating?\nHow does the amount of games played affect skill rating gain?\nMore games with same skill rating = gain less rating?\nCan we still use outcome based systems like Elo?\nHow do you determine if a SBMM system is good?\nWhat API’s are available?\nAre there overlaps in metrics that can be used across different genres of games?"
  },
  {
    "objectID": "introduction.html#investigating-skill-based-matchmaking-in-video-games",
    "href": "introduction.html#investigating-skill-based-matchmaking-in-video-games",
    "title": "Introduction",
    "section": "",
    "text": "Chess Image Source\n\n\nIn this day and age, access to technology and internet connection has allowed for the culmination of numerous facets of human interaction. With the inclusion of online gaming services, there are even more ways of interacting with others through the form of games.\nMany types of games have been born because of these online gaming services with a popular form of this being competitive gameplay. Since competing against other human players can be more challenging and interesting, this form of gaming has become wildly popular in our modern times. Competitive games in their respective categories (MOBA, Shooter, Strategy, etc. games) have become so popular that they have their own “eSports” or electronic sports scenes being streamed on various broadcasting networks. It is an understatement to say that the gaming industry is big, it’s enormous.1 With how large the industry and consumer-base is, it is extremely important for guidelines to be put in place for popular competitive games to sustain their competitive scene and player base.\n\n\n\nEsports Image Source\n\n\nWith the popularity of competitive gaming and its future growth, a necessity to (1) create an enjoyable experience and (2) provide players an incentive to continue playing needs to be addressed by developers.2 Sometimes this falls into the realms of marketing and design, but in competitive games the essence of competition and fair-play are attributes that developers must pay attention to for players to keep playing.\nA way to answer both these issues in competitive video games is through the addition of a Skill Based Matchmaking (SBMM) system. This system aims to create balanced teams that have similar skill ratings in order to produce a competitive match. Though, many matchmaking systems are made so that a player’s skill rating is linearly determined by their past matches (wins and losses) compared to their opponents. Past created rating systems like Elo, Glicko, and Trueskill are some examples of these. 3 In the cited source, Aram Ebtekar and Paul Liu give this introduction to simple skill rating systems like Elo before moving onto their own novel algorithms that includes the simplicity of traditional skill rating systems while including Bayesian thinking. The purpose of this paper is to introduce their novel Bayesian rating systems for competition formats that include multiple participants. This is an approach that I wanted to investigate more into as I believe that the Elo system is well made but that the algorithm just needed a bit more tweaking to work in modern competitive team games.\nTo go more into these traditional rating systems, we can dive into the history of the Elo system to get an idea of the foundations of more advanced rating systems. At its core, a rating system hopes to determine how good a player is at a certain game. The elo system was made exactly for that reason in the Chess world. Developed by Professor Arpad Elo in 1959 for Chess, the Elo system essentially took the skill rating between two players going against each other to determine the probability of who will win the Chess match. Obviously, the better player of the two will most likely win and therefore have a higher probability. The other player will thus have a lower probability. From here, the binary result of the match (win/loss) will determine how much the losing player loses from their skill rating points and how much the winning player gains. In the Elo system, the winning player takes a certain amount of points from the losing player thus increasing their skill rating points and the losing player losing skill rating points. The system is unique in that the initial skill ratings of the players determine how much they lose/gain. Say the worse rated player took an underdog win against the better rated player, then the worse player will take a much higher amount of rating points from the better player. If the situation was flipped where the worse player loses to the better rated player as expected, then the amount taken from the worse player will be a lot less. This Elo system has even been adopted in other games like Scrabble and Go as well as sports like Tennis, Bowling, and Basketball.4\n\n\n\nElo Formula Image Source\n\n\nGoing back to modern competitive games, there are many more aspects of these games that must be taken into consideration. Many popular competitive games include aspects like teamplay and coordination. So an innately one-person scalar rating in the Elo system being used in team games can be troublesome to calculate a team’s skill rating. So to consider the idea of teamplay and coordination is crucial in creating an accurate skill rating. Going more into this, each player has their own style of playing the game and therefore using an outcome-based algorithm like the Elo system is dangerous. It does not capture the overall complexity of competitive team games. Another aspect that isn’t addressed in the Elo system is the measurement of an individual’s performance/effort in a specific match. If a player played well compared to their usual performance, then their efforts will be lost if their rating is determined solely by the outcome of the match.5 In this cited source, Aghdaie and et. al. examine how nonlinear models as a function of the players’ and teams’ features. Whats more interesting is that this article explains their metrics of success in their experimentations (how to determine if their rating system is good or not). They also illustrate their two different approaches to creating balanced matches with a probability of winning prediction model and their competitive balance prediction model. I hope to look more into this article and applying their findings in different mainstream competitive games.\nCurrently, skill rating algorithms is largely uncharted territory as many games employ different aspects of performace. Additionally, many ideas of how to build these rating algorithms are still in development. So in this final project I will go down the rabbit hole of skill rating systems. I plan to investigate different viewpoints of skill rating systems and use game developers’ open API’s to take in data from numerous games to find possible ways of improving skill rating systems in each of those video games."
  },
  {
    "objectID": "introduction.html#investigating-skill-based-matchmaking-in-games",
    "href": "introduction.html#investigating-skill-based-matchmaking-in-games",
    "title": "Introduction",
    "section": "",
    "text": "Chess Image Source\n\n\nIn this day and age, access to technology and internet connection has allowed for the culmination of numerous facets of human interaction. With the inclusion of online gaming services, there are even more ways of interacting with others through the form of games.\nMany types of games have been born because of these online gaming services with a popular form of this being competitive gameplay. Since competing against other human players can be more challenging and interesting, this form of gaming has become wildly popular in our modern times. Competitive games in their respective categories (MOBA, Shooter, Strategy, etc. games) have become so popular that they have their own “eSports” or electronic sports scenes being streamed on various broadcasting networks. It is an understatement to say that the gaming industry is big, it’s enormous.1 With how large the industry and consumer-base is, it is extremely important for guidelines to be put in place for popular competitive games to sustain their competitive scene and player base.\n\n\n\nEsports Image Source\n\n\nWith the popularity of competitive gaming and its future growth, a necessity to (1) create an enjoyable experience and (2) provide players an incentive to continue playing needs to be addressed by developers.2 Sometimes this falls into the realms of marketing and design, but in competitive games the essence of competition and fair-play are attributes that developers must pay attention to for players to keep playing.\nA way to answer both these issues in competitive video games is through the addition of a Skill Based Matchmaking (SBMM) system. This system aims to create balanced teams that have similar skill ratings in order to produce a competitive match. Though, many matchmaking systems are made so that a player’s skill rating is linearly determined by their past matches (wins and losses) compared to their opponents. Past created rating systems like Elo, Glicko, and Trueskill are some examples of these. 3 In the cited source, Aram Ebtekar and Paul Liu give this introduction to simple skill rating systems like Elo before moving onto their own novel algorithms that includes the simplicity of traditional skill rating systems while including Bayesian thinking. The purpose of this paper is to introduce their novel Bayesian rating systems for competition formats that include multiple participants. This is an approach that I wanted to investigate more into as I believe that the Elo system is well made but that the algorithm just needed a bit more tweaking to work in modern competitive team games.\nTo go more into these traditional rating systems, we can dive into the history of the Elo system to get an idea of the foundations of more advanced rating systems. At its core, a rating system hopes to determine how good a player is at a certain game. The elo system was made exactly for that reason in the Chess world. Developed by Professor Arpad Elo in 1959 for Chess, the Elo system essentially took the skill rating between two players going against each other to determine the probability of who will win the Chess match. Obviously, the better player of the two will most likely win and therefore have a higher probability. The other player will thus have a lower probability. From here, the binary result of the match (win/loss) will determine how much the losing player loses from their skill rating points and how much the winning player gains. In the Elo system, the winning player takes a certain amount of points from the losing player thus increasing their skill rating points and the losing player losing skill rating points. The system is unique in that the initial skill ratings of the players determine how much they lose/gain. Say the worse rated player took an underdog win against the better rated player, then the worse player will take a much higher amount of rating points from the better player. If the situation was flipped where the worse player loses to the better rated player as expected, then the amount taken from the worse player will be a lot less. This Elo system has even been adopted in other games like Scrabble and Go as well as sports like Tennis, Bowling, and Basketball.4\n\n\n\nElo Formula Image Source\n\n\nGoing back to modern competitive games, there are many more aspects of these games that must be taken into consideration. Many popular competitive games include aspects like teamplay and coordination. So an innately one-person scalar rating in the Elo system being used in team games can be troublesome to calculate a team’s skill rating. So to consider the idea of teamplay and coordination is crucial in creating an accurate skill rating. Going more into this, each player has their own style of playing the game and therefore using an outcome-based algorithm like the Elo system is dangerous. It does not capture the overall complexity of competitive team games. Another aspect that isn’t addressed in the Elo system is the measurement of an individual’s performance/effort in a specific match. If a player played well compared to their usual performance, then their efforts will be lost if their rating is determined solely by the outcome of the match.5 In this cited source, Aghdaie and et. al. examine how nonlinear models as a function of the players’ and teams’ features. Whats more interesting is that this article explains their metrics of success in their experimentations (how to determine if their rating system is good or not). They also illustrate their two different approaches to creating balanced matches with a probability of winning prediction model and their competitive balance prediction model. I hope to look more into this article and applying their findings in different mainstream competitive games.\nCurrently, skill rating algorithms is largely uncharted territory as many games employ different aspects of performace. Additionally, many ideas of how to build these rating algorithms are still in development. So in this final project I will go down the rabbit hole of skill rating systems. I plan to investigate different viewpoints of skill rating systems and use game developers’ open API’s to take in data from numerous games to find possible ways of improving skill rating systems in each of those video games."
  },
  {
    "objectID": "introduction.html#hypothesis",
    "href": "introduction.html#hypothesis",
    "title": "Introduction",
    "section": "Hypothesis:",
    "text": "Hypothesis:\nWith more exploring of available data and better understanding what I can do with my project idea, I will modify my project scope as I work on it. For now, I will try to uncover some key aspects of certain competitive video games that are key in determining a players’ skill rating. Additionally, I hope to find any overlapping aspects between genres of games that might carry weight in determining skill rating.\nI believe that at each rank class for competitive video games that have ranking ladders there should be some indication of player match data that illustrates players’ skill rating. I hope to find this answer in this project."
  },
  {
    "objectID": "data_gathering.html#my-process",
    "href": "data_gathering.html#my-process",
    "title": "Data Gathering",
    "section": "My Process",
    "text": "My Process\nSo the process for retrieving information that I used for this project is as follows:\nFirst, I used the function that the Riot API offers which gives me a list of player names and their account ID’s in a certain rank. So in order to get a descriptive data set, I decided to retrieve an equal amount of players from each rank division at the same tier of that rank division. More specifically, I manually chose the ranks “Iron, Bronze, Silver, Gold, Platinum, Emerald, and Diamond” and the tier II for each rank division. So I requested a list of 205 player account names/their respective player ID’s for each rank (Iron II, Bronze II, Silver II, etc.)\nSecondly after getting a list of players in their rank, I looped through the player usernames and requested the player’s information on the Riot API in order to retrieve their ‘puuid’ as this is required in order to retrieve data from their played matches. So as I loop through the player usernames I get their puuid.\nThirdly, I take the puuid for each player and get their most recent 10 matches. So now, for each player puuid, I get a list of 10 match ID’s that I will later loop through as well.\nFinally, I loop through the 10 most recent matches ID’s and take the ID’s to put into another Riot API function that takes a match ID as a parameter and outputs/returns a very large dictionary containing the recordable match data performed by the players during the match as well as other metadata that I can use for organizationaly purposes. That being said, each match data has a something called a queueId. This is important because I only want to retrieve information from the queue ladder called ‘Ranked Solo/Duo 5v5’. Going into the Riot API documentation, I find that the queueId I want for this task would be a queueId of 420. So by looping through the match data, I filter out the matches that have a queueId of 420 and ignore all other matches. By doing so, the method I chose to replace those rows of the wrong queue ladder type would be to simply append rows of NA’s. This would have to be removed later in Data Cleaning. Also, I added the respective rank division in a separate column of each data set. This might be helpful if I were to concatenate all the ranks into a single data frame.\nAfter retrieving and storing it in data frames in my code, the only thing left is to write the data frames into csv excel files. After doing that, I am left with 7 different data sets from this process which is one excel file for each respective rank division at tier II.\nI did another process after this later for text data. I used the same exact process but this time only extracting individual player positions they are playing in the match and also their champion (fictional character within the game) that they chose. This text data will later be used for classification. This can be found in the data folder as well labeled as ‘text data’. \nChallenger Data Set in R  Now that I have this process of acquiring data sets, I decided to retrieve more data through R from the same API but using different functions. The main difference this time is that I am looking for data from extremely high ranked players in League of Legends.\nSo how this works is that after the rank division “Diamond”, there are 3 more divisions that dynamically change based on the total sum of a player’s skill rating points. The points are determined by Riot’s Skill Rating algorithm. So after “Diamond” comes “Masters” then “Grandmaster” and finally “Challenger”. Each of those ranks don’t have tiers and are differentiated at dynamically changing skill rating points thresholds. For example, the threshold to become a “Challenger” in rank is to reach a total of 800 League Points (hypothetically).\nKnowing that, I decided to retrieve more data on players for League of Legends but this time I will be inspecting the match data of the top 300 players on the leaderboard and their recent match data. This is possible because Riot API has a separate function specifically for players on the “Challenger” ranked ladder. And so using the same process as before for other players, I created a dataset filled with match data from the top 300 players in North America and their recent ‘Ranked Solo/Duo 5v5’ matches. Again, filtering the matches with queueId = 420 and storing the desired match data into a data frame. This time, everyone is ranked “Challenger” so I will not be labeling each match with the rank.\nSo now, I have an additional data set in the form of a csv file for “Challenger” players.\n——————————- INCLUDE IMAGES OF SNAPSHOTS OF DATASET ———————————–\n——————————- Maybe show snippets of code of how I retrieved data ———————————–"
  },
  {
    "objectID": "data_gathering.html#introduction-of-data-source",
    "href": "data_gathering.html#introduction-of-data-source",
    "title": "Data Gathering",
    "section": "Introduction of Data Source",
    "text": "Introduction of Data Source\n7 Rank Divisions Data Set in Python The primary API (Application Programming Interface) that I will be accessing to receive data for my Data Science Project is the Riot API provided by Riot Games. The competitive video game that I would like to primarily research about and obtain data for is the game League of Legends (LoL). Since this game has been around since 2009 and that the game features many many different possible recordable information, I found LoL to be the perfect subject for my Data Science data-driven project. What’s more is that the Riot API includes many options to retrieve information from.\n\n\n\nRiot Image Source\n\n\nOne of the biggest reasons I chose LoL as the primary video game to research about is, again, the amount of information I can include in my dataset but also the ease of access in this information from the Riot Games API. Unlike many other games, the Riot API for LoL allows any users or developers to have free access to many functions. A function that really caught my attention and influenced me to choose the Riot API and LoL is the function that allows users to find lists of player names and their respective ID’s. This is significantly useful because my research topic relates to how to determine a player’s respective rank based on their benchmarks of match data. By being able to have access to these I am thus able to retrieve the player’s most recent games and filtering their ranked games to get their most serious effort in terms of match data.\n\n\n\nKim “Deft” Hyuk-kyu at LoL Worlds 2022 Championship, Image Source\n\n\nFrom domain knowledge, the ladder queue called “Ranked Solo/Duo 5v5” is the most commonly played queue and is considered the best way to compare a player’s skill rating in most regions. This queue features the option to play a match of five players versus 5 players of equal skill rating. This data is in fact included in the API when retrieving a certain match’s data. Each match has information about which participants are in the match and their respective ‘puuid’. Then each participant would have their own information for each category of data which can be easily indexed after retrieving the match data."
  },
  {
    "objectID": "data_gathering.html#my-retrieval-process",
    "href": "data_gathering.html#my-retrieval-process",
    "title": "Data Gathering",
    "section": "My Retrieval Process",
    "text": "My Retrieval Process\nSo the process for retrieving player match that I used for this project is as follows:\n#Packages Used:\nimport requests\nimport pandas as pd\nimport numpy as np\nfrom time import sleep\nFirst, I used the function that the Riot API offers which gives me a list of player names and their account ID’s in a certain rank. So in order to get a descriptive data set, I decided to retrieve an equal amount of players from each rank division at the same tier of that rank division. More specifically, I manually chose the ranks “Iron, Bronze, Silver, Gold, Platinum, Emerald, and Diamond” and the tier II for each rank division. So I requested a list of 205 player account names/their respective player ID’s for each rank (Iron II, Bronze II, Silver II, etc.) through my get_league() function:\n\n\nCode\n#function get all summoner_names in a certain division\n#like GOLD, DIAMOND, PLATINUM\n#param: division as string, riot API key\n#return: puuid as string\ndef get_league(division, riot_api_key):\n    request_url = (\"https://na1.api.riotgames.com/lol/league/v4/entries/RANKED_SOLO_5x5/\" + division + \n                   \"/II?page=1\" + \"&api_key=\" + riot_api_key) #create correct request url\n    resp = requests.get(request_url) #get response after requesting from url\n    players = resp.json() #get dict of page 1 of players in certain division\n    league_list = [] #init empty list to append player summoner names\n    for dict in players: #loop thru each player in the dict\n        player = dict['summonerName'] #add the summoner name to empty list\n        league_list.append(player)\n    return league_list\n\n\nSecondly after getting a list of players in their rank, I looped through the player usernames and requested the player’s information on the Riot API in order to retrieve their 'puuid' as this is required in order to retrieve data from their played matches. So as I loop through the player usernames I get their puuid. To do this I made a function called get_puuid():\n\n\nCode\n#function get puuid from summoner name\n#param: player name as string, riot API key\n#return: puuid as string\ndef get_puuid(summoner_name, riot_api_key): \n    request_url = \"https://na1.api.riotgames.com/lol/summoner/v4/summoners/by-name/\" + summoner_name\n    request_url_api = request_url + \"?api_key=\" + riot_api_key #create request url\n    resp = requests.get(request_url_api) #get response\n    if resp.status_code == 200:\n        player_info = resp.json() #parse player info\n        if 'puuid' in player_info: #only looking for dictionary where 'puuid' exists\n            puuid = player_info['puuid'] #retrieve only puuid to use later\n    return puuid\n\n\nThirdly, I take the 'puuid' for each player and get their most recent 10 matches. So now, for each player puuid, I get a list of 10 match ID’s that I will later loop through as well. The get_matches() function performs this:\n\n\nCode\n#function to get 10 match ID's with puuid\n#param: puuid as string, riot API key\n#return: match id's as list of strings \ndef get_matches(puuid, riot_api_key): \n    match_url = (\n        \"https://americas.api.riotgames.com/lol/match/v5/matches/by-puuid/\" +\n        puuid +\n        \"/ids?start=0&count=10\" +\n        \"&api_key=\" +\n        riot_api_key\n    ) #create request url\n    resp = requests.get(match_url) #request with url\n    matches = resp.json() #parse it\n    return matches #we get the 10 most recent matches of a player\n\n\nFinally, I loop through the 10 most recent matches ID’s and take the ID’s to put into another Riot API function that takes a match ID as a parameter and outputs/returns a very large dictionary containing the recordable match data performed by the players during the match as well as other metadata that I can use for organizationaly purposes. That being said, each match data has a something called a queueId. This is important because I only want to retrieve information from the queue ladder called 'Ranked Solo/Duo 5v5'. Going into the Riot API documentation, I find that the queueId I want for this task would be a queueId of 420. So by looping through the match data, I filter out the matches that have a queueId of 420 and ignore all other matches. By doing so, the method I chose to replace those rows of the wrong queue ladder type would be to simply append rows of NA’s. This would have to be removed later in Data Cleaning. Also, I added the respective rank division in a separate column of each data set. This might be helpful if I were to concatenate all the ranks into a single data frame.\nFirst is the function to get the most recent 10 match ID’s. The function is called get_matches():\n\n\nCode\n#function to get 10 match ID's with puuid\n#param: puuid as string, riot API key\n#return: match id's as list of strings \ndef get_matches(puuid, riot_api_key): \n    match_url = (\n        \"https://americas.api.riotgames.com/lol/match/v5/matches/by-puuid/\" +\n        puuid +\n        \"/ids?start=0&count=10\" +\n        \"&api_key=\" +\n        riot_api_key\n    ) #create request url\n    resp = requests.get(match_url) #request with url\n    matches = resp.json() #parse it\n    return matches #we get the 10 most recent matches of a player\n\n\nThen is the function to get the specific match data that I want. This was done with the function player_data():\n\n\nCode\n#function to get specific types of data from match data\n#param: puuid as string, match_data as dict\n#return: win(true/false), kills, deaths, \n#damageDealtToObjectives,  damageDealtToTurrets, visionScorePerMinute,\n#totalDamageDealt, totalDamageTaken, totalMinionsKilled, \n#goldEarned, individualPosition, time in minutes\n##these variables were determined by domain knowledge\n##columns = ['win','kills','deaths','dmgObj','dmgTurr','vision_score','totalDmg','totalDmgTaken','totalMinions','gold','lane','time']\ndef player_data(puuid, match_data):\n    match = np.nan\n    if 'info' in match_data: #only looking for the data where 'info' dictionary exists\n        if match_data['info']['queueId'] == 420:\n            player_index = match_data['metadata']['participants'].index(puuid) #get index of player in the match\n            #because the dictionary is made according to the index of the player's puuid in the initial dict\n            win = match_data['info']['participants'][player_index]['win'] #win or loss (true/false)\n            kills = match_data['info']['participants'][player_index]['kills'] #number of kills in the match\n            deaths = match_data['info']['participants'][player_index]['deaths'] #number of deaths in the match\n            dmgObj = match_data['info']['participants'][player_index]['damageDealtToObjectives'] #dmg to objectives in the match\n            dmgTurr = match_data['info']['participants'][player_index]['damageDealtToTurrets'] #dmg dealt to objectives in the match\n            vision_score = match_data['info']['participants'][player_index]['visionScore'] #vision score in the match\n            totalDmg = match_data['info']['participants'][player_index]['totalDamageDealt'] #total damage dealt in the match\n            totalDmgTaken = match_data['info']['participants'][player_index]['totalDamageTaken'] #total damage taken in the match\n            totalMinions = match_data['info']['participants'][player_index]['totalMinionsKilled'] #total minions killed in the match\n            gold = match_data['info']['participants'][player_index]['goldEarned'] #amount of gold earned in the match\n            position = match_data['info']['participants'][player_index]['individualPosition'] #which position/lane the player played in that match\n            time = (match_data['info']['gameDuration'])/60 #match duration in minutes\n            match = pd.Series([win, kills, deaths, dmgObj, dmgTurr, vision_score, totalDmg, totalDmgTaken, totalMinions, gold, position, time],\n                          index=['win','kills','deaths','dmgObj','dmgTurr','vision_score','totalDmg','totalDmgTaken','totalMinions','gold','position','time'])\n    return match\n\n\nFinally, the function get_match_data() that uses the player_data() function to get data and store it into a dataframe for dataset building:\n\n\nCode\n#function to get match DATA with a list of match id\n#param: puuid as string, match ID's as list of strings, riot API key, empty df\n#empty df should have columns with these names in this order:\n#['win','kda','dmgObj','gold','vision_score','lane','time','game_type']\n#return: updated df with data\ndef get_match_data(puuid, matches, riot_api_key, empty_df):\n    for match in matches:\n        match_data_url = (\n            \"https://americas.api.riotgames.com/lol/match/v5/matches/\" +\n            match + \n            \"?api_key=\" +\n            riot_api_key\n        ) #create request url\n        match_data = requests.get(match_data_url) #request the url\n        match_data_parse = match_data.json() #parse the response\n        data_series = player_data(puuid, match_data_parse) #get all desired match variables/data\n        data_series2 = pd.DataFrame([data_series]) #change series to df\n        empty_df = pd.concat([empty_df, data_series2], ignore_index=True) #concat to empty df to add to the dataset\n\n    return empty_df\n\n\nNow putting this together, the steps to build this dataset:\n\nUse get_league() function to get 205 summoner names in a given division\nLoop over the list returned by get_league() to run through each player\nGet 'puuid' of each player\nGet recent 10 matches of each player\nGet match data if the match is ranked solo/duo 5v5 on summoner's rift\nOutput as dataframe\n\nSample code that it put it all together for Iron II rank:\n\n\nCode\n#init empty df with desired variables for IRON\ndf_iron = pd.DataFrame(columns=['win','kills','deaths','dmgObj','dmgTurr','vision_score','totalDmg','totalDmgTaken','totalMinions','gold','position','time'])\n\n#create list of all summoner names in division iron tier 2 (IRON II)\nleague_list = get_league('IRON', riot_api_key)\n#run through the necessary functions to update df with desired match data\nfor summoner in league_list:\n    puuid_summoner = get_puuid(summoner, riot_api_key) #getting puuid of player\n    matches_summoner = get_matches(puuid_summoner, riot_api_key) #get recent 10 matches with puuid\n    df_iron = get_match_data(puuid_summoner, matches_summoner, riot_api_key, df_iron) #update df with match data\n#to categorize this data of Iron II players, I will manually add a column with their respective rank\ndf_iron['rank'] = 'iron'\n\n\nAfter retrieving and storing it in data frames in my code, the only thing left is to write the data frames into csv excel files. After doing that, I am left with 7 different data sets from this process which is one excel file for each respective rank division at tier II.\nI did another process after this later for text data. I used the same exact process but this time only extracting individual player positions they are playing in the match and also their champion (fictional character within the game) that they chose. This text data will later be used for classification. This can be found in the data folder as well labeled with ‘text data’. \nChallenger Data Set in R  Now that I have this process of acquiring data sets, I decided to retrieve more data through R from the same API but using different functions. The main difference this time is that I am looking for data from extremely high ranked players in League of Legends.\nSo how this works is that after the rank division \"Diamond\", there are 3 more divisions that dynamically change based on the total sum of a player’s skill rating points. The points are determined by Riot’s Skill Rating algorithm. So after \"Diamond\" comes \"Masters\" then \"Grandmaster\" and finally \"Challenger\". Each of those ranks don’t have tiers and are differentiated at dynamically changing skill rating points thresholds. For example, the threshold to become a \"Challenger\" in rank is to reach a total of 800 League Points (hypothetically).\nKnowing that, I decided to retrieve more data on players for League of Legends but this time I will be inspecting the match data of the top 300 players on the leaderboard and their recent match data. This is possible because Riot API has a separate function specifically for players on the \"Challenger\" ranked ladder. And so using the same process as before for other players, I created a dataset filled with match data from the top 300 players in North America and their recent 'Ranked Solo/Duo 5v5' matches. Again, filtering the matches with queueId = 420 and storing the desired match data into a data frame. This time, everyone is ranked \"Challenger\" so I will not be labeling each match with the rank.\nSo now, I have an additional data set in the form of a csv file for \"Challenger\" players.\nThis was all done in R in the .rmd file which can be found here.\nText Data Set Retrieval (Python) \nIn addition to the numerical record data that I retrieved, I also retrieved a simple text dataset from the Riot API as well. I followed the exact same process as I did with my Python code I showcased. The changes I made were made in the player_data() function where I extracted different categories of player data. Specifically, I extracted the 'championName' and the 'individualPosition' match data. 'championName' is the fictional character being played by the player and 'individualPosition' is the position that the player is playing in that specific match.\nHere is the altered code for player_data():\n\n\nCode\ndef player_data(puuid, match_data):\n    match = np.nan\n    if 'info' in match_data: #only looking for the data where 'info' dictionary exists\n        if match_data['info']['queueId'] == 420: #only ranked matches are wanted\n            player_index = match_data['metadata']['participants'].index(puuid) #get index of player in the match\n            #because the dictionary is made according to the index of the player's puuid in the initial dict\n            champion = match_data['info']['participants'][player_index]['championName'] #the champion played\n            position = match_data['info']['participants'][player_index]['individualPosition'] #number of kills in the match\n\n            match = pd.Series([champion, position],\n                          index=['champion','position'])\n    return match"
  },
  {
    "objectID": "data_cleaning.html#cleaning-process",
    "href": "data_cleaning.html#cleaning-process",
    "title": "Data Cleaning",
    "section": "Cleaning Process",
    "text": "Cleaning Process\nAll the raw data that I retrieved from the Riot API can be found in the link above^. And details about how I retrieved the data along with the code of how I did the retrieval can be found in the “Data Gathering” tab.\n\n\n\nRiot Image Source\n\n\n\nimport pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\nPython Cleaning One of the first things after retrieving the data is of course importing the data set from a .csv file. In my case, since I retrieved many matches of different recordable data from each rank division I had seven different data sets of match data to import. This was simply done using the package from Pandas to read .csv files and importing them into Python. Also, it is worth noting that the code that I used to import uses the a relative path that is the same as seen on github. The code for importing:\n\n\nCode\n#file path to data\niron_path = '../../data/raw-riot-data/league data/league_iron_data.csv'\nbronze_path = '../../data/raw-riot-data/league data/league_bronze_data.csv'\nsilver_path = '../../data/raw-riot-data/league data/league_silver_data.csv'\ngold_path = '../../data/raw-riot-data/league data/league_gold_data.csv'\nplatinum_path = '../../data/raw-riot-data/league data/league_platinum_data.csv'\nemerald_path = '../../data/raw-riot-data/league data/league_emerald_data.csv'\ndiamond_path = '../../data/raw-riot-data/league data/league_diamond_data.csv'\n\n#import all .csv files of each ranked division match data\n#all blank entries in the dataset will be set as NaN by pandas\niron_df = pd.read_csv(iron_path)\nbronze_df = pd.read_csv(bronze_path)\nsilver_df = pd.read_csv(silver_path)\ngold_df= pd.read_csv(gold_path)\nplatinum_df= pd.read_csv(platinum_path)\nemerald_df= pd.read_csv(emerald_path)\ndiamond_df = pd.read_csv(diamond_path)\n\n\nAfter importing the .csv files and putting them in properly named variables, I actually first examined the original .csv files before deciding on what to clean first. What I noticed off the bat is that each rank divison match data set contained many many rows of \"NaN\" data. This is most likely due to how I retrieved the data as seen in the “Data Gathering” tab. If the match queueId was not equal to '420' then I would add a row of \"NaN\" values for that match in my dataset. I realized this was probably the best way as I could simply drop those rows in the future when I clean my dataset. After trying to drop the rows that had 'NaN'’s I realized that the output would be an empty data frame. Upon further examination, I noticed that there was a mysterious column labeled as '0' that contained 'NaN'’s for every single row. Which means after using the .dropna() function I would be essentially dropping every single row.\nKnowing that, I decided to use the .drop() function and setting axis=1 to drop the column '0' for every single rank division match data. After this, I attempted the .dropna() function again on each rank divison data set and fortunately it worked as planned. At a glance, many rows were eliminated this way (on average like 40% of all matches were dropped) but what was also interesting to see is that higher ranked players had less dropped rows. This meant they played more ranked matches recently (when I retrieved the data) than lower ranked players.\n\n\nCode\n#cleaning each imported dataframe:\n\n#every data set has a column called '0' that turns into NaN after read_csv()\n#eliminate that col for each dataframe:\niron_df = iron_df.drop('0', axis=1)\nbronze_df = bronze_df.drop('0', axis=1)\nsilver_df = silver_df.drop('0', axis=1)\ngold_df = gold_df.drop('0', axis=1)\nplatinum_df = platinum_df.drop('0', axis=1)\nemerald_df = emerald_df.drop('0', axis=1)\ndiamond_df = diamond_df.drop('0', axis=1)\n\n#now remove all rows that contain NaN\n#leaves us with no empty rows\niron_df = iron_df.dropna()\nbronze_df = bronze_df.dropna()\nsilver_df = silver_df.dropna()\ngold_df = gold_df.dropna()\nplatinum_df = platinum_df.dropna()\nemerald_df = emerald_df.dropna()\ndiamond_df = diamond_df.dropna()\n\n\nAfter having a much more cleaned dataset, I planned on changing some text data found in the 'position' column of the dataset. Since all other text data in the data set was lowercased, I decided to lowercase this entire column of text data as well for easier use later on. Again, I did this for every rank division data set.\n\n\nCode\n#clean the text data found in column 'position' for each division\n#lowercase all the strings found in this column\niron_df['position'] = iron_df['position'].str.lower()\nbronze_df['position'] = bronze_df['position'].str.lower()\nsilver_df['position'] = silver_df['position'].str.lower()\ngold_df['position'] = gold_df['position'].str.lower()\nplatinum_df['position'] = platinum_df['position'].str.lower()\nemerald_df['position'] = emerald_df['position'].str.lower()\ndiamond_df['position'] = diamond_df['position'].str.lower()\n\n\nFinally, I wanted to use CountVectorizer function from the sklearn module in order to count the frequency of how many times each 'position' value was seen in all the matches combined. Thus, this required me to combine all the rank division data frames into one big data frame of all the matches and rank divisions. This was done using Panda’s .concat() function. Then I used CountVectorizer and .sum() on the resulting data frame to create a small dataframe that put the 'position' values as the index and the frequency of each value under one column. While doing this, I noticed that some matches of a player had the 'position' value equal to 'invalid' meaning they most likely disconnected or was away from keyboard (afk) during the whole match. And so I dropped the rows that had a 'position' value of 'invalid'.\n\n\nCode\n#use CountVectorizer to count how often each position occurs in all the matches combined\n\n#first combine all the rank divison match data together:\nleague_combined = pd.concat([iron_df, bronze_df, silver_df, gold_df, platinum_df, emerald_df, diamond_df])\n\n#drop any rows that have 'invalid' as in the 'position' column\n#these matches are most likely due to players being afk during the whole match\nleague_combined = league_combined[league_combined['position'] != 'invalid']\n\n#now use CountVectorizer\nvectorizer = CountVectorizer()\ntest = vectorizer.fit_transform(league_combined['position'])\ndf_count_vectorized = pd.DataFrame(test.toarray(), columns=vectorizer.get_feature_names_out())\n\n#now sum the total number of each positions played from all matches\nposition_sum = df_count_vectorized.sum()\n\n\nSince I dropped a few more rows after combining, I decided to output the combined data frame into one .csv file as the cleaned data set for the 7 rank division match data sets that I inputted. Additionally, I outputted the small data frame containing the frequency of each ‘position’ value with their respective values as the index into its own .csv file. Outputted files: position_sum_cleaned.csv and league_combined_cleaned.csv.\nI then copied my cleaning process for the raw text data retrieved from the Riot API as well. The cleaned .csv file can also be found in the “cleaned_riot_data” folder.\n\n\nCode\n#write cleaned data into .csv file:\n#league_combined.csv + position_sum.csv\nleague_combined.to_csv('league_combined_cleaned.csv', index = False)\nposition_sum.to_csv('position_sum_cleaned.csv', index = True)\n\n\n\nR Cleaning In this section, I decided to work on cleaning the \"Challenger\" ranked players data set that I retrieved through the Riot API as well as detailed in the “Data Gathering” tab. This was mainly done in R and so I decided on working on cleaning the data set in R as well.\nWhile using R I noticed that after retrieving the data, that the data set did not have the same issues seen in my Python data set where there were missing rows of match data. It seems there was less work to be done in this data set.\nAs such, there was not much work to be done with this data set. I did the same process as before as I retrieved a basically the same match data format as before in Python but this time in R with the top 300 players in North America. In this case, I noticed again that the values in 'position' were uppercase so I lowercased all the values in every row in that column. Also, I noticed that there wasn’t a mysterious '0' column this time so less work was needed in this case too.\nI felt that this data set should be combined into the other combined data set for the 7 rank divisions. As such, I deemed it necessary to add a column in the challenger data set to display the appropriate rank \"Challenger\" for each row. So I included a new column into the challenger data frame called 'rank' like I did for the other rank divisions.\nWhen writing the dataframes into a .csv file, I felt that the Challenger data set should be made into a separate one on its own as I might perform analysis on just Challenger players. So writing the Challenger data set would make it convenient for me in the future. Additionally, I wrote the combined data set (7 rank divisions + Challenger rank) into a .csv file.Outputted files: chall_data_cleaned.csv and league_combined_with_chall_cleaned.csv.\n\n\nCode\n```{r packages}\n#packages\nsuppressPackageStartupMessages(suppressWarnings(library(tidyverse)))\n```\n\n\n```{r import_chall_data}\n#load in challenger data .csv\nchall_data &lt;- read.csv(\"../../data/raw-riot-data/league data/league_chall.csv\")\n```\n\n```{r clean}\n#lowercase all the values in 'position' column\nchall_data$position &lt;- tolower(chall_data$position)\n\n#using logical index, keep all rows that don't have 'invalid' in 'position' column\nchall_data &lt;- chall_data[!chall_data$position == 'invalid',]\n\n#add a column called 'rank' and put 'challenger' in each row\nchall_data$rank &lt;- 'challenger'\n\n```\n\n```{r combine}\n#combine with other combined data set\n#import combined data set\ncombined &lt;- read.csv(\"../../data/cleaned_riot_data/league_combined_cleaned.csv\")\n\n#combine both data frames with rbind()\ncombined_chall &lt;- rbind(combined, chall_data)\n\n```\n\n```{r csv}\n#write combined_chall and chall_data into .csv files\nwrite.csv(combined_chall, \"league_combined_with_chall_cleaned.csv\", row.names = FALSE)\nwrite.csv(chall_data, \"chall_data_cleaned.csv\", row.names = FALSE)\n\n```"
  },
  {
    "objectID": "naive_bayes.html#naive-bayes-classification-introduction",
    "href": "naive_bayes.html#naive-bayes-classification-introduction",
    "title": "Naive Bayes",
    "section": "",
    "text": "Objective To develop a model that can predict unseen data to some classification is the primary purpose of Naive Bayes Classification. So to reach this objective of making a model that can accurately predict some class given sample data, this process would then employ multiple statistical concepts. \nFoundational Knowledge Naive Bayes requires the use of Bayes’ Theorem which is a probability concept that illustrates the probability of some situation, hypothesis, or case occurring based on prior understandings (prior probabilities). Thus, Naive Bayes is grounded in training probabilities from frequencies of features for the purpose of classification predictions.  In Naive Bayes, for it to be “naive” means that the features/variables being used for the classification prediction are independent of other variables.\n\n\n\nBayes Theorem Image Source\n\n\n\nSteps The concept of Naive Bayes employs prior probabilities, the likelihood of data collected per class label, output a posterior probability for each class, and finally assign the input with a class label with the highest posterior probability. \nThe Aim of Naive Bayes in this Project As mentioned before, in order to find ways of enhancing competitive video games’ skill-based matchmaking systems there needs to be analysis of how certain variables within a game determines one rank. So to do this, I aim to use Naive Bayes to create a prediction model that will output a prediction for data inputs. By using the collected values of variables from ranked players and their associated ranks as class labels, I have everything I need to utilize Naive Bayes in building a classification algorithm that will predict some unseen player data’s rank.  This will require me to first train my model with my dataset and then later be tested with unseen data. \n\n\n\nNaive Bayes Image Source\n\n\nDifferent Variants of Naive Bayes\n\nGaussian Naive Bayes: This is when the features are continuous and the values follow a Gaussian Distribution. Since it assumes features for each class are Gaussian distributed, then within each class they would find the mean and standard deviation for each feature for classification.\nMultinomial Naive Bayes: This time the features are assumed to follow a multinomial distribution. This type of Naive Bayes is pretty common with text data that utilize word counts for text classification.\nBernoulli Naive Bayes: Since Bernoulli is about some outcome being one or the other, this type of Naive Bayes assumes features are binary meaning the values could be one of two options: Present or Absent, 1 or 0, True or False."
  },
  {
    "objectID": "naive_bayes.html#splitting-the-dataset",
    "href": "naive_bayes.html#splitting-the-dataset",
    "title": "Naive Bayes",
    "section": "Splitting the Dataset",
    "text": "Splitting the Dataset\nAn important step in preparing data for Naive Bayes Classification is to split the dataset into training, validation, and testing subsets. This is important because when building the model for predictions, we want the model to avoid overfitting onto the training data. This means that the model only correctly performs with the training dataset. To make a good classification model, one would look to make a model that performs well in general. The splitting will be 80% training, 10% validation, and 10% testing.\n  The training data subset would be used to teach the model the patterns of the features being used for classification. I like to think the model learns the general benchmark or description of each class which can be used to compare with future unseen data to output a prediction.  Sometimes the validation part of the model building process isn’t included but it is an important step. This step utilizes the learned model from the training set to further tune the hyperparameters of the model. This step is to prevent overfitting of the data to the training data subset. Basically, this step is to test the model so far and to adjust anything if needed.  Now with the testing set, it is the part where the final evaluation of the model’s performance on unseen data. This is to test how general the model and how effective it is.\n\nSubsection: Feature Selection for Record Data\nLink to Source Record Data: Record Data Source \nLink to source of feature selecting code on Github: Feature Select Record Data Code \nIn this section I look into identifying the most important and relevant features of the dataset in the training set. This was done with pearson correlation, merit performance metric, and iterrating through all combination of features in the training data set also known as Correlation-based Feature Selection (CFS). \nAfter using CFS on my record data, I was given the output of feature 3, 5, and 8 which were the Damage to Objectives per minute, Vision score per minute, and Minions farmed per minute features that maximized my performance metric (merit). Thus from this we can confirm that these features would be the features that should be used in my Naive Bayes classification model to improve the model accuracy and computation time. \nAfter performing this on the dataset, I was curious as to see which subset of features would be outputted after removing the roles “jungle” and “utility” as they showed the most outlier-like values during EDA. And after going through the feature selection process again, the features 5 and 8 were outputted as the best subset of features to maximize merit. Thus we can confirm that vision score per minute and minions farmed are the best features in predicting rank as these features overlap with the features outputted previously before removing jungle and utility positions. \nMoving forward, I will still include column 3 and positions jungle and utility in the model to test the overall effectiveness of rank predicting for the general player population which includes all positions played.\n\n\nSubsection: Feature Selection for Text Data\nLink to Text Data on Github: Source of Text Data \nMy idea for Naive Bayes for text data was utilize the champions played by players in each match to train a model to predict which position each champion typically plays. Although, this is less about predicting and more so about determining which position each champion typically plays according to retrieved match data. \nSince the features in this case are the Champions played, then the use of feature selection for my text data is not needed at all as each feature is unique/independent and is significant in determining the feature’s classification.\n\n\nNaive Bayes Record Data Results\nLink to Naive Bayes Code for Record Data on Github: NB Code for Record Data \nNote Numerics for Ranks: 0 = Iron, 1 = Bronze, 2 = Silver, 3 = Gold, 4 = Platinum, 5 = Emerald, 6 = Diamond, 7 = Challenger\nFor my record data, since the values are continuous I decided on using Scikit-Learn’s function called GaussianNB() which allowed me to fit my model to the the training dataset. I then used this model to create predictions for unseen data in the Validation dataset as well as the Testing dataset. This is what I found: \nAccuracies: I compared the accuracy of the predicition model to each split dataset (training, validation, and testing) to compare how overfit the model (or not overfit). And here are the accuracy results:\n\n\n\nAccuracies Image\n\n\nFrom these results we can see that the accuracies are actually quite similar with each other for training, validation, and testing datasets. So, thankfully there doesn’t seem to be any overfitting. That being said, the overall accuracy does seem to be low with about 20% accuracy in correctly predicting the rank of unseem match data. But, since the model is generally performing the same across all subsets of data, then I confidently conclude that overfitting is not occurring but not for underfitting. Since my accuracy is low, I suspect that my model is not learning patterns from the retrieved data. This was somewhat what I was expecting as there are too many factors in a competitive Ranked Match for League of Legends and that I either did not get enough variables from my data retrieval or that it simply an impossible task to do accurately. \nRecall and Precision: Next, I looked into recall and precision of each class or Rank from the predicition model and this is what I found:\n\n\n\nPrecision and Recall Image\n\n\nPrecision describes what the ratio of all the predicted positives, which were actually positive. From the plot shown above, we can see that the precision scores are generally pretty low across the board except for ranks: Bronze, Gold, and Challenger. Bronze and Challenger ranks are on the opposite sides of the spectrum so this could be because the model was able to learn what lower-ranks and what top players look like. However, I do not really understand why the rank Gold has such a high precision score as they are part of the middle pack in terms of rank.\nRecall on the other hand seems to be more consistent, though consistently low. Recall describes the ratio of the number predicted as true among the actually true. So the model in this case does not really get the actually true cases too often with the highest recall being a ratio of about 0.35. \nCombining recall and precision, you get the F1-Score which explains how well the model performs. In this case, it outputs about 0.19 which follows the model accuracy result of about 20% accuracy. \nConfusion Matrix: Now for the confusion matrix to illustrate how the trained model performed on the testing dataset:\n\n\n\nConfusion Matrix Image\n\n\nAfter showing the results and performance metrics, the confusion matrix does seem to illustrate how poorly it was able to correctly predict classes. Something that I noticed in this plot is that the 2nd rank or Silver seems to have no predictions at all while the 3rd rank or Gold has the majority of predictions. This was also highlighted earlier in the precision score. This investigation is leading me to believe that the ranks Silver and Gold have some anomalies in the data.\nConclusions: I think if I were to do this again, I would possibly look into retrieving more unique features for my dataset. After observing the performance of the training model on the Validation and Testing set, I realized that the data might be way too vague for the model to learn the patterns needed to accurately predict some unseen player’s rank based solely on their match data. \nThough this adds to the difficulty of creating a well-working Skill-Based Matchmaking System for competitive video games like League of Legends as there are simply too many factors that can influence the outcome of a game. That being said, I did find that feature selecting did slightly work in making a more accurate model. From my Naive Bayes code, I made a model that had about a 20% accuracy in predicting rank but without feature selecting there was a slight decrease in accuracy (about 2% decrease in accuracy). This meant that there are indeed variables within a game that should be valued when determining a player’s skill level. There are still, however, many more variables that I could look into if I were to continue this project so there are possible features in match data that might benefit this rank prediction model.\n\n\nNaive Bayes Text Data Results:\nLink to Naive Bayes Code for Text Data on Github: NB Code for Text Data\nDoing somewhat similar task but with text classification this time, I performed a similar process as the record data. The only difference is that I used a vectorizer from Scikit-Learn to process the string data as numerical data before fitting the text data into a NB Model. Also, I used MultinomialNB() from Scikit-Learn as well to fit the text data into classes.\nWhat I did in this section was basically retrieve a dataset of the champions played in a match and the role the champion played by the player. I would then train a model to predict unseen data on where certain champions might play in the unseen match data. I then calculated metrics for how well this model worked on the retrieved text data with associated labels. \nAccuracies:\nSince this model was straightforward and performed as well as I expected I did not include a validation subset this time for the sake of time. Here is what I found in regards to the accuracy of the NB model:\n\n\n\nAccuracies Image\n\n\nAs you can see the accuracy is about 0.86 for both training and testing datasets. This means that the model was able to recognize which characters (champions) played in what roles typically. Nothing else to say as this model worked pretty effectively. I will say that the accuracy is not perfect because in this game the players have no restrictions for what positions their characters plays which leads to unique team compositions sometimes. Though through social/community consensus, some characters are best fit in certain roles. This consensus is thus what we see in this model and in the plot shown.\nSince the accuracy is high in both training and testing, I can confidently say that the model does not seem to overfit. Additionally, since the accuracy is high that there does not seem to be underfitting from the model. \nPrecision, Recall, and F1:\nWith such high accuracies, I wanted to confirm it with recall, precision, and finally F1-Score:\n\n\n\nPrecision, Recall, and F1-Score Image\n\n\nWe can thus confirm that the model does indeed show promising performance metrics based on the overall precision, recall, and F1-Score. All three metrics hover around 0.86 score similar to accuracy.\nConfusion Matrix:\nWith such promising metrics, I am expecting to see a confusion matrix that has a dense diagonal line:\n\n\n\nText Data Confusion Matrix\n\n\nAs hoped, the matrix seems to fully illustrate why the metrics are so high. The model was able to correctly predict the true classes for unseen data with little incorrect predictions. Positions Jungle and Mid seem to have some overlaps in incorrect predictions which might be because the champions playing in the Mid roles might also have some play in the Jungle role or vice versa.\nConclusions:\nThe model has outputted promising metrics showing that the text data was able to be properly classified with the given training data. It tells us that the consensus of where champions play in a ranked match for League of Legends is strongly expressed by the players as the model was able to predict where each champion is typically played despite having no restrictions of what position they can play. Overall, the NB model performed very well and it can be seen in the confusion matrix with the dense diagonal line shown."
  },
  {
    "objectID": "dim_red.html#project-outline",
    "href": "dim_red.html#project-outline",
    "title": "Dimensionality Reduction",
    "section": "",
    "text": "In this section of my project, I hope to utilize some Dimensionality reduction techniques on the data that I gathered from the Riot API to better suit the dataset for future modeling. As seen in the feature selection tab, I was able to find the most relevant variables to use for my Naive Bayes classification modeling. Using what I found from that venture, I hope to compare the feature selection results with results from using Dimensionality Reduction techniques, Principal Component Analysis (PCA) and t-Distributed Stochastic Neighbor Embedding (t-SNE), on the same dataset. After performing the techniques, I want to explore how the variance of the dataset changes through visualizations. This will help me compare the results of my feature selection results with the results from PCA and t-SNE.  \n\n\n\nDimensionality Reduction Image Source\n\n\nKey Libraries  I will be coding these techniques up on Python by using core functions from modules like Pandas, Numpy, and Scikit-Learn. General data management will come from Pandas and Numpy while the techniques for PCA and t-SNE will mainly come from the Scikit-Learn library. To create visualizations as mentioned in my outline above, I will use the matplotlib library to do this.  \nimport pandas as pd\nimport numpy as np\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE\nimport matplotlib.pyplot as plt\nHow does this relate to my project?  As an aspiring Data Scientist, I hope to go more into Machine Learning, Deep Learning, and AI which means these techniques should be explored somewhat in order to understand fundamental processes that were later advanced. And with my desire to work on statistical analysis of games, I hope to explore these techniques on my retrieved dataset from the Riot API in order to understand the practicality of these techniques under this topic."
  },
  {
    "objectID": "dim_red.html#dimensionality-reduction-results-with-pca",
    "href": "dim_red.html#dimensionality-reduction-results-with-pca",
    "title": "Dimensionality Reduction",
    "section": "Dimensionality Reduction Results with PCA",
    "text": "Dimensionality Reduction Results with PCA\nThe cleaned data I used: Retrieved Match Data from Riot API\nThe code for performing PCA: PCA Code\nPCA Process  A process of feature extraction where all of the information being used is retained was done on the record data that I retrieved from the Riot API. Firstly, I did some cleaning again to normalize the record data as all features were time-dependent. I also removed the non-numerical variables so that PCA can be done properly. In hindsight, I could have encoded the categorical variables as numerics but I did also want to compare what I found from PCA with what I concluded in Feature Selection so I went with the original time-dependent features. \nNext, I used Scikit-Learn’s function to fit then transform the dataset to create multiple principal components. These principal components basically contained all information about each feature in some way. The features were combined in some linear fashion to result in a principal component. These transformations were done multiple times to create multiple principal components (created the same number of PC’s as the number of features). After creating multiple principal components, they were sorted from highest variance of transformed data points to lowest variance. The first component now having the highest variance, the second component having the second highest variance, and so on. \n\n\nCode\n#define PCA() as instance\n#without defining parameters in PCA process first\npca = PCA()\n\n#fit and transform the dataset with PCA \ncombined_pca = pca.fit_transform(combined_league_ranks)\n\n#reintroduce the class label (ranks) according to each row.\n#the rows should be in the same order as before.\ncombined_pca = pd.DataFrame(combined_pca)\ncombined_pca['rank'] = rank_col #will be helpful in visualizing\n\n\nVisualizing PCA  To visualize this, I created a scatterplot of the first and second principal component to see how varied the points look now after doing PCA transformations on the dataset: \n\n\nCode\n#assign color to each class label\neach_rank = rank_col.unique()\ndiff_colors = plt.cm.tab10(range(len(each_rank)))\nmap_color_rank = dict(zip(each_rank, diff_colors))\n#now map back to the combined_pca df\ncombined_pca['rank color'] = combined_pca['rank'].map(map_color_rank)\n\n#plot the PCA transformed dataset into scatterplot\nfor label in each_rank:\n    #subset dataset with each label\n    subset = combined_pca[combined_pca['rank']==label]\n    plt.scatter(subset[0], subset[1], c=map_color_rank[label], label=label)\n#title, labels, and legend\nplt.title('Scatterplot of First and Second Principal Component')\nplt.xlabel('First Principal Component')\nplt.ylabel('Second Principal Component')\nplt.legend()\n\n#save as .png\nplt.savefig('all_pc_TRANSFORMED.png')\n\nplt.show()\n\n\n\n\n\n1st and 2nd PC Scatterplot\n\n\nFrom the plot, the variance of the first principal component’s transformed data points is compared to the second principal component. Simply by looking at the x and y-axis, we can see the range of each principal component linearly transformed data points. The first principal component spanning much more and thus would logically have the highest variation. \nVisualizing Loadings of First Principal Component  After witnessing the variance of the first and second principal component, I wanted to see the loadings of the first principal component. \nThe loadings of each principal component explains how much a feature contributes to the linear transformation of the original dataset. This was done using Scikit-Learn’s PCA module as well since the PCA function they provide also offers a way to see the loadings of each principal component.\n\n\nCode\n#select the first principal component then get loadings\nloadings = pca.components_[0]\n\n#save the loadings into dataframe\nload_df = pd.DataFrame({'features': combined_league_ranks.columns, 'loadings': loadings})\n#print the loads for each feature\nprint(load_df)\n\n\n           features  loadings\n0         kills/min  0.000035\n1        deaths/min -0.000005\n2        dmgObj/min  0.132264\n3       dmgTurr/min  0.016178\n4  vision_score/min -0.000088\n5           dmg/min  0.988058\n6      dmgTaken/min  0.071493\n7       minions/min  0.000296\n8          gold/min  0.029582\nFrom the output of the loadings for the first principal component, we can see that there are basically no negative loadings meaning almost all features positively contributed to the generation of the first principal component. Additionally, the negative loadings were practically zero. What contributed the most by a mile to the generation of the first principal component was the damage per minute feature from the original dataset. \nNow to show these values in a visualization: \n\n\nCode\n#first convert loadings to absolute value as all negatives are basically 0\nload_df['absolute loads'] = np.abs(load_df['loadings'])\n#next sort by absolute loadings from highest magnitude to lowest\nsorted_load = load_df.sort_values(by='absolute loads', ascending=False)\n\n#now plot with features as x-axis and the loadings of each feature\nplt.figure(figsize=(10, 6))\nplt.bar(sorted_load['features'], sorted_load['loadings'])\nplt.title('Loadings of Each Feature for the First Principal Component')\nplt.xlabel('Each Feature')\nplt.ylabel('Loading Value')\nplt.xticks(rotation=45, ha='right')\n\n#save plot as .png\nplt.savefig('sorted_loads_PC.png', bbox_inches='tight')\n\nplt.show()\n\n\n\n\n\nLoadings Barplot\n\n\nFrom the simple barplot, we can confirm that the use of the feature \"damage per minute\" definitely contributed the most compared the all other features in the creation of the first principal component.  \nNow what does this mean? The use of loadings showed us how feature extraction could linearly transform the data points of all features in some way in order to create a well-varied spread of data points while retaining all information within the principal component. To compare to feature selection, this does not tell us which features offer the most information or impact on a Naive Bayes Classification model as that would depend on the transformed data points and their correlation with the class label (or rank in this case). Instead, it offers a method of transforming data to include more variance with reduced dimensionality. This would reduce computation time without losing as much information as feature selection. So in conclusion, we cannot completely compare which features offer the most impact for a classification model aftering doing PCA like what I did with feature selection. That step would have to be taken after transforming the data and training it into a classification model.  \nOptimal Number of Principal Components  The purpose of finding an optimal number of principal components from PCA is so that the resulting transformed dataset has a usable amount of variance so that a classification model is capable of learning the patterns of the transformed dataset. It is also to lessen the amount of dimensions the dataset has while trying to retain as much information as possible. This trade-off should force us to find the optimal number of principal components that would allow us to keep as much information as possible while reducing the amount of computation needed, lower the risk of overfitting so that models don’t learn noise or other specific patterns, and could help us find features that contribute the best to a classification model for example.  \nNow to do this, I took the cumulative sum of the variance RATIO from the total number of principal components that was captured before. There was an equal number of principal components as features: \n\n\nCode\n#get the explained_variance_ratio_ and plot the cumulative sum of it\nplt.plot(np.arange(1,10), np.cumsum(pca.explained_variance_ratio_))\n\n#x should be simply indexed by the number of principal comps\nplt.title('Cumulative Explained Variance RATIO With More Components')\nplt.xlabel('# components')\nplt.ylabel('cumulative variance ratio')\n\n#save as .png\nplt.savefig('optimal_PC_num.png', bbox_inches='tight')\n\nplt.show()\n\n#it seem the elbow first appears at 3 principal components\n\n\n\n\n\nCumulative Sum of PC Variance Ratio\n\n\nUsing a simple elbow method of the cumulative sum of the variance ratios of the number of principal components, we can determine what minimal number of principal components should give us the best amount of variance. And from the plot generated, the cumulative sum rate increase starts to diminish at about 3 principal components. Thus, the optimal number of principal components that should be used for PCA should be 3 principal components."
  },
  {
    "objectID": "dim_red.html#dimensionality-reduction-results-with-t-sne",
    "href": "dim_red.html#dimensionality-reduction-results-with-t-sne",
    "title": "Dimensionality Reduction",
    "section": "Dimensionality Reduction Results with t-SNE",
    "text": "Dimensionality Reduction Results with t-SNE\nThe code for performing t-SNE: t-SNE Code\nVisualizing t-SNE Distribution  Using Scikit-Learn’s library for a t-SNE function, I was able to conveniently transform and fit my record data into a 2-dimensional non-linear version. The idea behind t-SNE is to put more emphasis on data points from the original dataset that are very similar to each other. This is done by measuring two data points similarity through measurements like the Euclidean distance formula. It then compares each data point with all other data points from the original dataset to represent the similarity between points. The model would then adjust the distribution to emphasize similar data points. The t-SNE process then iterates through multiple configurations of points in a low-dimensional space that would best preserve the discovered pairwise similarities of data points found in the higher-dimensional space.  \nAnother point that should be mentioned with t-SNE is the tuning of the perplexity parameter. With a lower perplexity, the distribution of points follows more heavily with the data points from the original dataset that are close to each other. This is known as following the patterns of the “local” structure. As you go higher in perplexity, the distribution follows more of the “global” structure which means the relationships/patterns of the points that are farther apart in the original dataset are considered more and more. Using a perplexity of somewhere in the middle will help show the relationship of the points while illustrating both the local and global relationships of the original dataset.  \nTo visualize this, I chose to generate a 2-dimensional transformation of the original dataset with t-SNE and plotted the dimensions against each other with varying perplexity parameter values: \n\n\nCode\n#define perplexity parameter to iterate through\nperplex = [5,30,50,100]\n\n#for coloring the plot, convert categorical class labels to numerical representations\nlabels = rank_col.astype('category').cat.codes\n\n#iterate through perplexity and also generate a plot\ncount = 0\nfor per in perplex:\n\n    #count used for subplotting\n    count += 1\n\n    #set TSNE with parameters\n    tsne = TSNE(n_components=2, perplexity=per, random_state=42) #use same seed for each perplexity case\n    #fit/transform with record dataset\n    current_tsne = tsne.fit_transform(combined_league_ranks)\n\n    #now we should have a 2 dimensional representation of original dataset\n    #plot the TSNE transformation with class labels for coloring\n    plt.subplot(2,2,count)\n    plt.scatter(current_tsne[:, 0], current_tsne[:, 1], c=labels, cmap='viridis', s=10)\n    plt.xlabel('t-SNE First Dimension')\n    plt.ylabel('t-SNE Second Dimension')\n    plt.title(f't-SNE with Perplexity = {per}')\n\nplt.tight_layout()\n#save as .png\nplt.savefig('tSNE_perplexities.png', bbox_inches='tight')\n\nplt.show()\n\n\n\n\n\nt-SNE with Different Perplexities\n\n\nFrom the plot, it definitely seems that a pattern in the relationships of the data points in the higher dimension existed as I increased the perplexity. Immediately at 30 perplexity, there was a curving shape being formed from the originally well spread data points."
  },
  {
    "objectID": "dim_red.html#comparing-the-results-from-pca-and-t-sne",
    "href": "dim_red.html#comparing-the-results-from-pca-and-t-sne",
    "title": "Dimensionality Reduction",
    "section": "Comparing the Results from PCA and t-SNE",
    "text": "Comparing the Results from PCA and t-SNE\nEffectiveness of Each Technique  From the visualizations that I generated for both processes and taking into account the transformations done using both techniques, I feel PCA and t-SNE both had their unique takes on dimensionality reduction. On one hand, PCA had the benefit of being explored in more depth on how each feature can be used to transform the data into different, lower dimensional versions of the original dataset. It was simpler to understand with loadings since the transformation process is linear. On the other hand, t-SNE was able to show the similarity relationships of each data point from the original dataset in a lower dimensional data distribution. t-SNE also had the option to tune the distribution differently with the use of perplexity which allowed for further examination of how farther apart data points contributed in a lower-dimensional space.  \nIn regards to retaining all information from all features in the original dataset, I think t-SNE showed more potential in preserving the structure of the data better with the use of perplexity as the relationships of all data points can be included with some perplexity. In PCA, the linear combinations sometimes included negative loadings meaning some features actually negatively contributed to the generation of principal components which grows my concern over the use of all features. But I think that is also where the trade-off can occur, since PCA can capture in which direction of the original features offers maximum variance. PCA thus can identify global patterns with this. This is something defintely to consider as there are times when you would want to consider the global structure more or the local structure more. This is an aspect where t-SNE could be better as tuning perplexity down could offer more insight on local structures. Another trade-off that I could think of is that PCA is definitely quicker in computational time since it works with linear operations whereas t-SNE took much longer since it looked into non-linear relationships and similarities. That being said, PCA logically could only look into linear relationships and might not discover non-linear relationships. t-SNE might have a leg up in this case as the process can capture non-linear relationships more.\nVisualization with Each Technique  For visualizing the generated data from PCA and t-SNE, I would say that PCA might have an upper hand as the visualizations are much easier to understand. The use of linear operations in generating a lower dimensional distribution is much easier to wrap my head around. For example, the well spread distribution of the first and second principal component was pretty easy to understand. The spread of the data points for a principal component simply spread across its associated axis. For t-SNE, the visualization better explained the intricate patterns found in the non-linear generation of the data points. \nRelating Both Back to Project Topic  After going through each technique with the project record dataset, I felt I was not able to uncover more on the global relationship between points with PCA. With the use of t-SNE I was able to see how the relationship of each data point changed with higher perplexity versus the non-unique distribution of the lower perplexity distribution which looked similar to what I found with PCA. With the multiple facets of data being generated in a competitive video game like League of Legends, it is understandable that there are more non-linear relationships between features than linear ones. This would thus enable t-SNE to be a much better suited dimensionality reduction technique in my opinion."
  },
  {
    "objectID": "decision_tree.html#methods-on-random-forest",
    "href": "decision_tree.html#methods-on-random-forest",
    "title": "Decision Tree and Random Forest",
    "section": "Methods on Random Forest",
    "text": "Methods on Random Forest\nWith a given dataset of observations and multiple variables, Random Forest (RF) can be done to generalize the data so that results aren’t overfitting and has the potential to render noise as less impactful on the final prediction. So, the key idea in RF models is to use the raining dataset to build many, many decision trees where each decision tree are randomly made based on the training dataset. This randomness, again, reinforces the idea of generalization on the final result.\nTo go into more detail, decision trees are randomly made and what this means is that each decision tree takes a random subset of the training dataset with each node of the tree only considering a random subset of the features. This will create multiple decision trees where each tree will have different nodes with different decisions for the random subset of variables. Later, the test data will run through the model to determine what each random tree predicts. \nFinally after each tree outputs a prediction, the RF will select a majority voted prediction for the test data sample. And this will be done with all test samples within the test dataset. By introducing randomness and then aggregating the overall predictions to output a final result, it helps to improve the model’s ability to properly classify new data using the training data. It will utilize generalization of the data rather than possibly focusing on outliers/noise which can negatively affect the model’s predictions."
  },
  {
    "objectID": "decision_tree.html#baseline-of-class-distribution",
    "href": "decision_tree.html#baseline-of-class-distribution",
    "title": "Decision Tree and Random Forest",
    "section": "Baseline of Class Distribution",
    "text": "Baseline of Class Distribution\nIn this step, I took the distribution of the number of counts of the ranks that appeared in the record dataset. This is used later to do a random number generation based on the weights of the distribution which would act as the predictions. This generation of predictions is then compared to a uniformally generated distribution of classes. From here, I calculated the accuracy, precision, recall, and F1 scores and this is what I found: \nRandom Classifier metric scores:\nAccuracy Score: 0.1206\nPrecision Score: 0.12346353020210461\nRecall Score: 0.1206\nF1 Score: 0.12141405817891071\nPrecision, Recall, and F1 Scores: (array([0.11662727, 0.10995185, 0.1458671 , 0.13333333, 01288, 0.0811245 , 0.14705882, 0.10090238]), array([0.13143872, 0.11729452, 0.13081395, 0.11925287, 0.11290323, 0.1011011 , 0.12475378, 0.12424242]), array([0.12359081, 0.11350456, 0.13793103, 0.12590064, 0.12032885, 0.09001783, 0.13499112, 0.11136261]), array([1126, 1168, 1376, 1392, 1426,  999, 1523,  990], dtype=int64))\nAs seen in the output accuracy, precision, recall, and F1 scores, it makes sense to see a total accuracy probability of about 0.125 as the distribution of classes for the record data is somewhat uniform meaning the total accuracy is about 1/total number of class or 8 which is about 0.125.Next, we can see that total Precision, Recall, and F1-Score sort of follows the distribution. This is because the scores are also relatively close to 1.125 again though a little off since the weights are not perfectly uniform. To go into more details on each class’ precision, recall, and f1 scores the last output shows how each class performed. And we can see that the average precision, recall, and f1 scores are close to the aggregate scores.\nThe code I used:\n\n\nCode\n# Simple histogram plot to show the distribution of each rank in the record dataset. \nsns.countplot(x='rank', data = combined_league_ranks)\nplt.title('Counts of Each Rank In Record Data')\nplt.xticks(rotation = 90)\nplt.show()\n#the number of samples with given ranks range from ~530 to ~840.\n\n\n# Now get an actual count of each rank.\nrank_dist = combined_league_ranks['rank'].value_counts().reset_index()\nrank_dist.columns = [\"ranks\",\"counts\"]\nprint(rank_dist)\n\n\n#add a column of the probability of the distribution of class labels\nrank_dist['prob'] = rank_dist['counts']/sum(rank_dist['counts'])\n#add another column to convert the ranks into numbers for the random classifier algorithm\nlabel_encode = LabelEncoder()\nrank_dist['ranks_num'] = label_encode.fit_transform(rank_dist['ranks'])\n\n# input the numbered classes and the weights of each class into random.choices() to generate 10,000 sampled dataset\nrank_weights = random.choices(list(rank_dist['ranks_num']), weights=list(rank_dist['prob']), k = 10000)\n\n\n#then input into random classifier code\n#Code was provided by DSAN 5100 shared code\nypred=[]\nmax_label=np.max(rank_weights)\nfor i in range(0,len(rank_weights)):\n    ypred.append(int(np.floor((max_label+1)*np.random.uniform(0,1))))\n\n#print accuracy, precision, and recall\nprint(\"Random Classifier metric scores:\")\nprint(\"Accuracy Score:\",accuracy_score(rank_weights, ypred))\nprint(\"Precision Score:\",precision_score(rank_weights, ypred, average='weighted'))\nprint(\"Recall Score:\",recall_score(rank_weights, ypred, average='weighted'))\nprint(\"F1 Score:\",f1_score(rank_weights, ypred, average='weighted'))\nprint(\"Precision, Recall, and F1 Scores:\",precision_recall_fscore_support(rank_weights, ypred))\n\n\n\nBasic Decision Tree Classifier Model\nIn this step, I decided to use a basic individual Decision Tree in order to create a classification for predicting class labels of test dataset samples. One of the biggest steps to do in making the most optimal Decision Tree model is to find the best hyperparameters for making a Decision Tree. \nTo find the best hyperparameters to use for an individual Decision Tree classifier, I found a great function by Scikit-Learn called GridSearchCV that takes models and predefined hyperparameter options to go through each combination of the parameters. After going through each combination of hyperparameters, the function can output (at least the output that I specified) an accuracy score of the model on the training dataset. The highest accuracy score is determined and the hyperparameters used to determine this accuracy is outputted as well. After finding the optimal parameters, the Decision Tree found that the highest accuracy it could achieve was about 20.6% accuracy. This is pretty close with what I found in Naive Bayes. \n\n\nCode\n# preset some options for hyperparameters then go through the combinations with GridShotCV\nparam_grid = {'max_depth': [None, 5, 10],'min_samples_split': [2, 5, 10, 20, 40, 80],'min_samples_leaf': [1, 2, 4, 8, 16, 32]}\n\n#split dataset 80/20 = training/testing\nx_train, x_test = train_test_split(combined_league_ranks, test_size=0.2, random_state=33)\n\n#pop 'rank' col to make target variables\ny_train = x_train.pop(\"rank\")\ny_test = x_test.pop(\"rank\")\n\n# now create basic decision tree classifier model\ndt_model = DecisionTreeClassifier()\n\n#find best parameters with predefined param_grid\ngridsearch = GridSearchCV(dt_model, param_grid, cv=5, scoring='accuracy')\ngridsearch.fit(x_train, y_train)\n\n#print the best accuracy found and the tuned hyperparameters to use\nprint(\"Optimal Hyperparameters:\",gridsearch.best_params_)\nprint(\"Training accuracy:\",gridsearch.best_score_)\n\n\nAfter finding the most optimal hyperparameter combination for the Decision Tree classifier, I fitted it with the testing dataset and got 20.3% accuracy. With this we can see that the model had about the same accuracy/error with the training and testing datasets. This was the tree that was created: \n\n\nCode\n#plot the decision tree itself\nplt.figure(figsize=(30,15))\nplot_tree(opt_dt_model, filled=True, rounded=True, fontsize=12)\nplt.savefig('basic_tree.png', bbox_inches='tight')\nplt.show()\n\n\n\n\n\nBasic Decision Tree\n\n\nAnd also a confusion matrix on the predictions made by the basic Decision Tree on test data: \n\n\nCode\n#output the predictions of the basic decision tree classifier\ntest_preds = opt_dt_model.predict(x_test)\nconf = confusion_matrix(y_test, test_preds)\nsns.heatmap(conf, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels= y_train.unique(), yticklabels=y_train.unique())\nplt.savefig('basic_tree_conf.png', bbox_inches='tight')\nplt.title('Confusion Matrix of a Decision Tree with Optimal Parameters')\nplt.show()\n\n\n\n\n\nBasic Decision Tree Confusion Matrix\n\n\nThe tree itself was pretty full of nodes and leaves so just visually seeing the structure was the best I could achieve in plotting the tree. More importantly, the confusion matrix made seemed pretty similar to the one I made in Naive Bayes tab where the distribution was pretty scattered and certain ranks took most of the predictions. Either way, it definitely showed why the accuracy was low (about 20%). This further emphasizes what I found earlier in my project where the dataset I retrieved was inherently complex and rank predictions might be difficult to achieve. So in the future, I think including more variables might help in determining the best variables to predict players’ ranks.\n\n\nRandom Forest Classifier Model\nFinally, I followed the same steps that I did with the basic Decision Tree model but now with a Random Forest model. I similarly used the GridSearchCV function to find the most optimal hyperparameters for the Random Forest model with the training dataset. I then found the accuracy of the training data to be about 23.3% with the Random Forest model. This is a slight improvement from what I found with the basic Decision Tree. \n\n\nCode\n#predefine parameter options\nparam_grid_rf = {'n_estimators': [50, 100, 150],'max_depth': [None, 5, 10, 15],\n    'min_samples_split': [2, 5, 10],'min_samples_leaf': [1, 2, 4]}\n\n#RF model\nrf_model = RandomForestClassifier(random_state=33)\n\n#now do gridsearch again on the RF model with diff combos of predefined parameter options\ngridsearch_rf = GridSearchCV(rf_model, param_grid_rf, cv=5, scoring='accuracy')\n#also fit with train data and targets\ngridsearch_rf.fit(x_train, y_train)\n\nprint(\"Optimal hyperparameters:\", gridsearch_rf.best_params_)\nprint(\"Optimal Model Accuracy: \", gridsearch_rf.best_score_)\n\n\nNow with the optimal parameters found, I created the Random Forest model again and fitted it with the training data. This time I found a score of about 23.8% accuracy which was exciting but overall still a very bad accuracy score for my model. \nSo making a plot for the Random Forest model is basically impossible as it would require me to plot every single individual tree from the model. I decided to skip this step and simply just plot a confusion matrix of the predicted output: \n\n\nCode\n#Plot confusion matrix of the new predictions with RF\ntest_preds_rf = opt_rf.predict(x_test)\nconf = confusion_matrix(y_test, test_preds_rf)\nsns.heatmap(conf, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels= y_train.unique(), yticklabels=y_train.unique())\nplt.savefig('rf_conf.png', bbox_inches='tight')\nplt.title('Confusion Matrix of Random Forest with Optimal Parameters')\nplt.show()\n\n\n\n\n\nRandom Forest Confusion Matrix\n\n\nThis confusion matrix looks a bit more spread out instead of focusing on specific ranks. What is consistent is that the ‘Challenger’ rank is still being correctly predicted massively compared to other ranks. Though, the diagonal of predictions of the ranks is a lot more apparent now. I feel like this confusion matrix illustrates well why the accuracy is slightly higher with Random Forest.\n\n\nConclusions\nAs stated before, the models used show why my dataset might be too complex to create predictions of player ranks from. Similar to what I found in my Naive Bayes section of my project, I noticed that my model produced an accuracy score of about 20% across the training and test datasets. This was a low accuracy score and therefore meant that my dataset might be inherently too complex to make a classifier model out of it. \nAfter doing this again with a basic Decision Tree model and a Random Forest model, I noticed the same ~20% accuracy of predicting the correct rank. This further emphasized my assumption that my dataset is inherently too complex and that I might need to include other variables than the ones I chose in order to better predict a player’s rank from their unseen match data. So in the future if I were to continue this project, I would definitely look to retrieve different record data and to try these classification models again to see if my scores change at all."
  },
  {
    "objectID": "conclusion.html#future-work",
    "href": "conclusion.html#future-work",
    "title": "Conclusions",
    "section": "Future Work",
    "text": "Future Work\nAs iterated many times before, I will most likely have to repeat a lot of these techniques again after I curate an improved dataset. This meant that I should include different/more features that might relate to determining a player’s skill rating. Another thing that I should focus on if I were to continue this project is to perform noise or outlier reduction techniques."
  },
  {
    "objectID": "conclusion.html#techniquesanalyses",
    "href": "conclusion.html#techniquesanalyses",
    "title": "Conclusions",
    "section": "",
    "text": "League of Legends Image Source\n\n\nTo reiterate my project scope, I hope to do my investigation on the mainstream video game League of Legends. This was because of the limited amount of available data that I could retrieve relating to player data. And the reason I am looking specifically at player data is so that I can find variables within the game that might distinctly separate skill rating classes of players. So to find some underlying trends/information out of the data of thousands of players, I used different techniques listed below and took away some insights:\n\nNaive Bayes\nDimensionality Reduction\nClustering\nDecision Tree\nRandom Forest\n\n\n\nMy first venture was using Naive Bayes to build a model that could potentially classify the rank of a player given their unseen match data. This idea dives right into my project scope as I believed that certain differently ranked players are distinct enough in match data. After going through this technique, my resulting model (even after feature selection) had about a 20% accuracy. This had a lot of implications relating to my project idea. It meant that my dataset did not show a clear enough pattern between rank classes to accurately classify an unseen player’s rank based on their match data. This could mean many things from retrieving the insignificant features to this being an inherently impossible task. I think moving forward, I would work on building a different dataset that includes more variables to possibly find more significant features that might better predict a player’s rank.\nSomething exciting that I did find was that there were indeed features within the game that should be valued more when determining a player’s rank. This was found with feature selection.\nOn a separate mini-project relating to Naive Bayes, I looked into how related are the fictional characters (champions) being played by players correlate to their chosen position. I found in this mini-project that there does seem to be a consensus of what position certain champions play despite having no restrictions on where they can be played. The model created in this case performed very well and showed that there seems to be a community driven agreement of what positions certain champions play the best.\n\n\n\nI found the use of different dimensionality reduction in my project. Namely, the use of Principal Component Analysis (PCA) and t-Distributed Stochastic Neighbor Embedding (t-SNE). Here is what I found using each method:\nI found that using t-SNE might have helped more in understanding my dataset better. This was because of the ability to tune the perplexity of dimensionally reducing my dataset with t-SNE. This allowed me to see how the relationship of points changed with higher perplexity which uncovered more about the global relationship between points in my dataset. Using a lower perplexity showed a relatively insignificant distribution of points similar to what I saw with PCA.\nI felt my visualization with t-SNE and the comparison visualization with PCA showed that my dataset was a lot more complex than I originally anticipated. This further emphasized what I found in my Naive Bayes step, that my retrieved dataset of player match data might be inherently too complex or contains too much noise for a classification model.\n\n\n\nIn this clustering step, I basically looked how different clustering techniques might play a role in my player match data dataset. I found that, again, my dataset was inherently really complex which led to my model having a low 20% accuracy. This step further emphasized what I found before but it did lead me to believe that I am lacking more unique variables and that noise might play a bigger role than I thought. So if I were to continue with this project, I would look to include more features into my dataset and employ noise or outlier reducing techniques.\n\n\n\nIn this step, I built a basic decision tree after using a Scikit-Learn function called GridSearchCV that looked for the highest accuracy with different combinations of hyperparameters for the given decision tree model. What I found was a similar classification model accuracy compared to what I found in Naive Bayes.\nThis just further emphasized the issue with my dataset being too complex or containing too much noise.\n\n\n\nIn this final technique, I used a Random Forest Classification model to compare what I found in the basic Decision Tree model as well as my Naive Bayes model. I found again 20% accuracy as my model accuracy score after optimizing hyperparameters. In the end I found the same results as I found in my first technique, Naive Bayes."
  },
  {
    "objectID": "conclusion.html#final-word",
    "href": "conclusion.html#final-word",
    "title": "Conclusions",
    "section": "Final Word",
    "text": "Final Word\nTrying to understand and improve a competitive game’s Skill Based Matchmaking System is a tall task for one person in one project, but investigating the nuances of a multi-faceted game was a fruitful endeavor in my opinion. I was able to understand the broader scope of the complexity of League of Legends through the game’s many different data-generating features. As an avid player in many different games across multiple genres, diving deep into one of the biggest competitive games in the world was truly an insightful journey."
  }
]